createdAt: "2019-08-12T09:31:47.241Z"
updatedAt: "2019-11-29T13:24:53.644Z"
type: "SNIPPET_NOTE"
folder: "a8a34bf81446463f9ca3"
title: "temp"
tags: []
description: "temp"
snippets: [
  {
    linesHighlighted: []
    name: "test_per_result_alerting.py"
    mode: "Python"
    content: '''
      # vim: set fileencoding=utf-8 :
      
      # [MIGRATION]
      # platform/functional/datamodel/suite_open_in_pivot/
      # test_open_in_pivot_generate_endpoint.py
      
      import json
      import os
      import pytest
      import urllib
      from helmut.util.rest_uris import RESTURIS as uri
      from pytest_splunk_base.fixtures import download_source
      from splunk_rest_wrapper.search.job.jobs import Jobs
      from pytest_splunk_testcube import params
      from pytest_splunk_marker import SplunkTest
      from pytest_splunk_marker import TestPlatform
      from pytest_splunk_marker import TestPriority
      from pytest_splunk_marker import TestDeployment
      from pytest_splunk_marker import TestInfra
      from pytest_splunk_base.testcase import BaseTest
      
      
      @SplunkTest(
          deployment_type=[TestDeployment.S1],
          infra_type=[TestInfra.ucp, TestInfra.aws_ec2],
          platform=[TestPlatform.windows, TestPlatform.linux])
      class TestOpenInPivotGenerate(BaseTest):
          """
          Tests the Open In Pivot REST Endpoints : Generating Data Models
          """
      
          @classmethod
          @pytest.yield_fixture(scope='class', autouse=True)
          def setup_teardown_class(cls, theatre_deployment):
              cls.search_heads = theatre_deployment.stage.search_heads
              cls.search_head = cls.search_heads.random_choice()
              cls.indexer = theatre_deployment.stage.indexers.random_choice()
              yield
      
          @params([
              {
                  'testname':
                      'Create Open In Pivot json With Foursquare Data with fields',
                  'search_string': 'index="foursquare"',
                  'fields': 'badges,timezone,venue,user,gender',
                  'field_coverage': None
              },
              {
                  'testname':
                      'Create Open In Pivot json With Foursquare Data '
                      'with field_coverage',
                  'search_string': 'index="foursquare"',
                  'fields': None,
                  'field_coverage': '0.5'
              },
              {
                  'testname':
                      'Create Open In Pivot json With index=_internal with fields',
                  'search_string': 'index=_internal|head 10',
                  'fields': 'clientip,status,uri,uri_path',
                  'field_coverage': None
              },
              {
                  'testname':
                      'Create Open In Pivot json index=_internal '
                      'with field_coverage',
                  'search_string': 'index=_internal|head 10',
                  'fields': None,
                  'field_coverage': '0.25'
              }
          ])
          @SplunkTest(priority=TestPriority.p1)
          def test_create_valid_open_in_pivot_datamodel(
                  self, foursquare_data, testname,
                  search_string, fields, field_coverage):
              """
              Create a Valid Open In Pivot Datamodel and check the response code.
              Tried to create Datamodel with GET, POST, PUT, DELETE
              """
      
              # Step 1: Declaration of Datamodel url and datamodel arguments
              open_pivot_uri = uri.URIS['OPEN_IN_PIVOT_GENERATE']
      
              kwargs = {'status_buckets': 300}
              sid = Jobs(self.search_head.rest).create(
                  'search {str}'.format(str=search_string), **kwargs).wait().sid
      
              url_args = ({"fields": fields, "sid": sid}
                          if not field_coverage else
                          {"sid": sid, "field_coverage": field_coverage})
      
              # Step 3: Make rest call, with all the methods GET, POST, PUT, DELETE
              # check the response code. For POST, PUT, DELETE logs the message why
              # those methods does not generate open in pivot datamodel
              for method in self.search_head.rest.conn.METHODS:
                  response, content = self.search_head.rest.conn.make_request(
                      method, open_pivot_uri,
                      urllib.urlencode(url_args), {'output_mode': 'json'})
                  if method is 'GET':
                      self.verify_equals(
                          response['status'],
                          self.search_head.rest.conn.SUCCESS[method],
                          'Expected response code {resp} '
                          'does not match the {m}'.format(
                              resp=response['status'],
                              m=self.search_head.rest.conn.SUCCESS[method]))
                  elif method is 'POST':
                      exp_msg = ('Cannot perform action "POST" without '
                                 'a target name to act on.')
                      parsed = json.loads(content)
                      msg = str(parsed['messages'][0]['text'])
                      self.verify_in(
                          exp_msg, msg,
                          ('Expected Message {exp_result} does not '
                           'match the message received {msg}').format(
                              exp_result=exp_msg, msg=msg))
                      self.verify_not_equals(
                          response['status'],
                          self.search_head.rest.conn.SUCCESS[method],
                          ('Expected response code {resp} '
                           'does not match the {m}').format(
                              resp=response['status'],
                              m=self.search_head.rest.conn.SUCCESS[method]))
                      self.logger.info('{method} is invalid action for '
                                       'reason {msg}'.format(method=method, msg=msg))
                  elif method is 'PUT':
                      exp_msg = "Requested invalid action 'PUT'."
                      parsed = json.loads(content)
                      msg = str(parsed['messages'][0]['text'])
                      self.verify_in(
                          exp_msg, msg,
                          ('Expected Message {exp_result} does not match the '
                           'message received {msg}').format(
                              exp_result=exp_msg, msg=msg))
                      self.verify_not_equals(
                          response['status'],
                          self.search_head.rest.conn.SUCCESS[method],
                          ('Expected response code {resp} does not '
                           'match the {m}').format(
                              resp=response['status'],
                              m=self.search_head.rest.conn.SUCCESS[method]))
                      self.logger.info('{method} is invalid action for '
                                       'reason {msg}'.format(method=method, msg=msg))
                  elif method is 'DELETE':
                      parsed = json.loads(content)
                      msg = str(parsed['messages'][0]['text'])
                      exp_msg = ('Cannot perform action "DELETE" without a target '
                                 'name to act on.')
                      self.verify_in(
                          exp_msg, msg,
                          ('Expected Message {exp_result} does not '
                           'match the message received {msg}').format(
                              exp_result=exp_msg, msg=msg))
                      self.verify_not_equals(
                          response['status'],
                          self.search_head.rest.conn.SUCCESS[method],
                          ('Expected response code {resp} does not'
                           'match the {m}').format(
                              resp=response['status'],
                              m=self.search_head.rest.conn.SUCCESS[method]))
      
                      self.logger.info('{method} is invalid action for '
                                       'reason {msg}'.format(method=method, msg=msg))
      
          @params([
              {
                  'search_cmd': '| inputcsv start=100 max=500 Starbucks.csv',
                  'fields': 'City,Brand',
                  'testname': 'Search Cmd with inputcsv'
              },
      
              {
                  'search_cmd': '| datamodel',
                  'fields': 'displayName, modelName',
                  'testname': 'Search Cmd with datamodel'
              },
      
              {
                  'search_cmd': 'search index=_internal | '
                                'stats count(eval(method="GET"))'
                                ' as GET, count(eval(method="POST")) '
                                'as POST by host',
                  'fields': 'host, GET, POST',
                  'testname': 'Search Cmd with stats'
              },
      
              {
                  'search_cmd': 'search index="_internal" | '
                                'transaction clientip maxspan=10m '
                                '| eval durationstr=tostring(duration,"duration")',
                  'fields': 'Time, Event',
                  'testname': 'Search Cmd with transaction and eval'
              },
      
              {
                  'search_cmd': 'search index="_audit" | audit',
                  'fields': 'user,validity',
                  'testname': 'Audit trail information that is stored '
                              'in the local audit index'
              },
          ])
          @SplunkTest(priority=TestPriority.p1, jira='SPL-149262')
          def test_with_variety_of_different_searches(
                  self, search_cmd, fields, testname):
              """
              Test with variety of different searches
              """
              # Step 1: Declaration of Datamodel url and datamodel arguments
              self.logger.info("Test of the search {} start".format(search_cmd))
              open_pivot_uri = uri.URIS['OPEN_IN_PIVOT_GENERATE']
      
              # Step 2: if search_cmd has Starbucks.csv then add oneshot
              if 'Starbucks.csv' in search_cmd:
                  starbucks_data = download_source('Starbucks.csv')
                  self.search_head.fileutils.send(
                      starbucks_data, self.search_head.splunk_home)
                  self.search_head.rest.create_input_oneshot(
                      name=os.path.join(
                          self.search_head.splunk_home, 'Starbucks.csv'))
      
              # Step 3: Create or run a Search and then grab the sid
              kwargs = {'status_buckets': 600}
              sid = Jobs(self.search_head.rest).create(
                  '{str}'.format(str=search_cmd), **kwargs).wait().sid
      
              url_args = {"fields": fields, "sid": sid}
      
              # Step 4: Make rest call, to generate open in pivot datamodel
              response, content = self.search_head.rest.conn.make_request(
                  'GET', open_pivot_uri, urllib.urlencode(url_args),
                  {'output_mode': 'json'})
      
              if search_cmd.startswith('|'):
                  self.verify_equals(
                      response['status'], '500',
                      'Expected response code {resp} does not match the {m}'.format(
                          resp=response['status'], m='500'))
              else:
                  self.verify_equals(
                      response['status'], '200',
                      'Expected response code {resp} does not match the {m}'.format(
                          resp=response['status'], m='200'))
      
    '''
  }
  {
    linesHighlighted: []
    name: "nightlysplunk"
    mode: "Python"
    content: '''
      @pytest.fixture(scope="session")
      def nightlysplunk(request):
          """
          nightlysplunk test fixture,
           - if splunk is pre-install:
           uses splunk in SPLUNK_HOME or --splunk-home
           - if --splunk-home or SPLUNK_HOME is given but splunk is not installed there:
           installs a nightly splunk instance into splunk_home and use it
           - if splunk home not given:
           installs a nightly splunk instance into a temp directory and use it
      
          Then starts splunk in the end.
      
          In fixture finalizer, splunk will be:
           - stopped if it's pre-installed
           - uninstall if it's installed by this plugin
      
          @return: A helmut splunk instance.
          """
          #hack fixture scope
          if hasattr(pytest.config, 'nightlysplunk_scope') and (pytest.config.nightlysplunk_scope in SCOPE_LIST):
              request.scope = pytest.config.nightlysplunk_scope
          splunk_branch = request.config.nightly_branch
          changelist = request.config.changelist
          product = request.config.product
          splunk_home = request.config.splunk_home
          postaction = request.config.postaction
          LOGGER.info('splunk_home=%s' % splunk_home)
          is_installed_by_me = False
      
          if not splunk_home:
              splunk = _install_nightlysplunk(splunk_branch, changelist, product)
              is_installed_by_me = True
              LOGGER.info(
                  "splunk_home not found. Set SPLUNK_HOME={0}. Download &install splunk branch={1}, "
                  "changelist={2}, product={3}".format(splunk.splunk_home, splunk_branch, changelist, product))
          else:
              LOGGER.info("splunk_home found:{0}. Using pre-installed splunk. ignore branch={1}, "
                          "changelist={2}, product={3}".format(splunk_home, splunk_branch, changelist, product))
              splunk = SplunkFactory.getSplunk(splunk_home=splunk_home, name="nightlysplunk")
              if not splunk.is_installed():
                  LOGGER.info("splunk is not installed at splunk_home. Installing splunk.")
                  splunk = _install_nightlysplunk(splunk_branch, changelist, product, splunk_home)
                  is_installed_by_me = True
              splunk.set_credentials_to_use(username=request.config.username, password=request.config.password)
          was_running = splunk.is_running()
          if not (was_running and request.config.donotstart):
              splunk.start(auto_ports=True)
      
          def fin():
              """
              finalizer for nightlysplunk test fixture
              """
              if postaction:
                  if postaction in ("uninstall", "remove", "destroy", "u"):
                      splunk.uninstall()
                  elif postaction in ("stop", "down", "s"):
                      if splunk.is_running():
                          splunk.stop()
                  elif postaction in ("run", "up", "r"):
                      if not splunk.is_running():
                          splunk.restart()
              else:
                  if is_installed_by_me:
                      splunk.uninstall()
                  else:
                      if not was_running:
                          splunk.stop()
      
          request.addfinalizer(fin)
          return splunk
    '''
  }
  {
    linesHighlighted: []
    name: ""
    mode: "Python"
    content: '''
      #!/usr/bin/python
      # vim: set fileencoding=utf-8 :
      
      """
      Meta
      ====
          $Id$
          $DateTime$
          $Author$
          $Change$
      """
      from __future__ import unicode_literals
      
      import httplib
      import json
      import logging
      import ssl
      import urllib
      import urlparse
      from base64 import b64encode
      
      import os
      import tarfile
      import tempfile
      import zipfile
      import gzip
      import binascii
      import pytest
      import requests
      import rip
      from polling import poll_for_condition
      from sys import platform as _platform
      from requests.auth import HTTPDigestAuth
      
      try:
          # The python standard library can be built without bz2 so we make bz2
          # usage optional.
          import bz2
      except ImportError:
          bz2 = None
      
      INDEX_WAIT = 120
      
      
      class PathNotFoundError(IOError):
          """
          Throw this error when the path you looking for is not found.
          """
          pass
      
      
      class FileNotFound(IOError):
          """
          Throw this error when file you looking for is not found.
          """
          pass
      
      
      class HECRequestException(Exception):
          """
          Throw this exception when HEC request failed.
          """
          pass
      
      
      def normalize_to_str(obj):
          """
          Utility to help normalize all objects and string
          to ascii representation.
      
          if unicode string -> ascii string
          if ascii string -> ascii string
          if object -> object.__str__()
      
          @type obj: object
          @param obj: strings or objects
      
          @rtype: ascii string
          @return: ascii representation of the object passed in.
          """
          if isinstance(obj, str):
              return obj
          elif isinstance(obj, unicode):
              return str(obj.encode('utf8'))
          else:
              return str(obj)
      
      
      def is_abs_path(path_value):
          """
          Workaround for INFRA-15819
      
          Check whether this is a abs path or not
          Below values are treated as abs path
              /opt/splunk
              C:\\opt\\splunk
      
          :param path_value: the path value
          :type path_value: str
      
          :rtype: bool
          """
          return (os.path.isabs(path_value) or (
                      len(path_value) > 2 and path_value[1] == ':'))
      
      
      class IndexLog(object):
          """
          Base class to index a log file.
      
          """
      
          def __init__(
                  self, logfile_name, logfile_dir, sourcetype, event_count, index,
                  source, username, password, mgmt_url, index_wait=INDEX_WAIT,
                  path_util=os.path, rest_settings=None):
              """
              @type logfile_name: string
              @param logfile_name: name of the log file
      
              @type logfile_dir: string
              @param logfile_dir: dir of the log file
      
              @type sourcetype: string
              @param sourcetype: name of sourcetype for the log file
      
              @type event_count: int
              @param event_count: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type source: string
              @param source: name of the source for the log file
      
              @type username: string
              @param username: the splunk username
      
              @type password: string
              @param password: the splunk password
      
              @type mgmt_url: string
              @param mgmt_url: the splunk managment url
      
              @type path_util: object
              @param path_util: the file path util
      
              @type index_wait: int
              @param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
              """
              # for tests/web/webdriver tests. there are params that will
              # set this up. ideally this should not be here.
      
              if ('config' in pytest.__dict__ and
                      'install_forwarder' in pytest.config.__dict__ and
                      pytest.config.install_forwarder):
      
                  if ('config' in pytest.__dict__
                          and 'forwarder_username' in pytest.config.__dict__):
                      pytest_username = pytest.config.forwarder_username
                  else:
                      pytest_username = None
      
                  if ('config' in pytest.__dict__
                          and 'forwarder_password' in pytest.config.__dict__):
                      pytest_password = pytest.config.forwarder_password
                  else:
                      pytest_password = None
      
              else:
      
                  if ('config' in pytest.__dict__
                          and 'admin_username' in pytest.config.__dict__):
                      pytest_username = pytest.config.admin_username
                  else:
                      pytest_username = None
      
                  if ('config' in pytest.__dict__
                          and 'admin_password' in pytest.config.__dict__):
                      pytest_password = pytest.config.admin_password
                  else:
                      pytest_password = None
      
              # set the management url regardless of forwarder or not.
              if ('config' in pytest.__dict__
                      and 'mgmt_url' in pytest.config.__dict__):
                  pytest_mgmt_url = pytest.config.mgmt_url
              else:
                  pytest_mgmt_url = None
      
              username = username or pytest_username or 'admin'
              password = password or pytest_password or 'changeme'
              mgmt_url = mgmt_url or pytest_mgmt_url
      
              self.logger = logging.getLogger(self.__class__.__name__)
              self.logfile_name = logfile_name
              self.logfile_dir = logfile_dir
              self.sourcetype = sourcetype
              self.event_count = event_count
              self.index = index
              self.source = source
              self.username = username
              self.password = password
              self.mgmt_url = mgmt_url
              self.index_wait = index_wait
      
              if rest_settings is None:
                  self.rest_settings = {}
              else:
                  self.rest_settings = rest_settings
      
              if ('config' in pytest.__dict__
                      and hasattr(pytest.config, 'saml_okta')
                      and pytest.config.saml_okta
                      and 'admin_username' in pytest.config.__dict__
                      and 'admin_password' in pytest.config.__dict__):
                  conn = rip.RESTConnectorReplacement(
                      username=pytest.config.admin_username,
                      password=pytest.config.admin_password,
                      app='search', uri_base=self.mgmt_url)
              else:
                  conn = rip.RESTConnectorReplacement(
                      username=self.username, password=self.password,
                      app='search', uri_base=self.mgmt_url)
      
              self.rest = rip.RESTInPeace(conn)
      
              # by default fwd rest and reciever rest is the same
              self.fwd_rest = self.rest
              if ('config' in pytest.__dict__ and
                      'install_forwarder' in pytest.config.__dict__ and
                      pytest.config.install_forwarder and
                      'forwarder_username' in pytest.config.__dict__ and
                      'forwarder_password' in pytest.config.__dict__):
                  conn = rip.RESTConnectorReplacement(
                      username=pytest.config.forwarder_username,
                      password=pytest.config.forwarder_password,
                      app='search', uri_base=self.mgmt_url)
                  self.fwd_rest = rip.RESTInPeace(conn)
      
              full_path = os.path.join(self.logfile_dir, self.logfile_name)
              if is_abs_path(full_path):
                  self.log_path = full_path
              else:
                  self.log_path = path_util.abspath(full_path)
      
              self.logger.info(
                  normalize_to_str("Log path: {lp}".format(lp=self.log_path)))
      
              src = (self.source.replace('\\\\', '\\\\\\\\')
                     if _platform == 'win32' else self.source)
              self.search_string = (
                  'index="{idx}" source="{src}" sourcetype="{srctype}"'.format(
                      idx=self.index, src=src, srctype=self.sourcetype))
      
          def search_string_with_timerange(self, earliest=0, latest='now'):
              """
              To provide a method that can specify the time range in log file level
              via log_file.search_string_with_timerange(), instead of modifying the
              search cmd string or uri params in each case params.
      
              :param earliest: set the earliest time , default is 0 means that starts
                               from earliest event date of log but not the from the
                               start of UTC epoch time.
              :param latest: set the latest time , default is now which used together
                             with earliest = 0 to set 'All time' timerange.
              :return: Return the search string
              """
              time_search_string = "{s} earliest={e} latest={l}".format(
                  s=self.search_string, e=earliest, l=latest)
              return time_search_string
      
          def set_rest_setting(self, endpoint, params, remote_rest=None):
              """
              Checks if a rest endpoint exist, if not creates it.  Otherwise just
              updates the endpoints parameters.
              """
              rest = remote_rest or self.rest
              name = params.pop('name')
              check_endpoint = getattr(rest, 'check_{}'.format(endpoint))
              create_endpoint = getattr(rest, 'create_{}'.format(endpoint))
              edit_endpoint = getattr(rest, 'edit_{}'.format(endpoint))
              wait_for_endpoint_to_be_created = getattr(
                  rest, 'wait_for_{}_to_be_created'.format(endpoint))
      
              if not check_endpoint(name):
                  create_endpoint(name=name, **params)
                  wait_for_endpoint_to_be_created(name)
              else:
                  edit_endpoint(name, **params)
      
              if check_endpoint(name) and endpoint == 'cloud_index':
                  self.validate_cloud_indexers(rest, name)
      
          def validate_cloud_indexers(self, rest, name):
              """
              To validate if all indexers have replicated the index from cluster
              master. In this case we get all the indexers present in indexer cluster
              and poll till each indexer has received index
              """
              self.logger.info("Verifying status of index created in indexers")
              cluster_config = json.loads(
                  rest.get_all_cluster_config(output_mode='json')[1])
              if 'entry' in cluster_config:
                  master_uri = (cluster_config[
                                'entry'][0]['content']['master_uri'])
                  conn = rip.RESTConnectorReplacement(
                      username=pytest.config.admin_username,
                      password=pytest.config.admin_password, app='search',
                      uri_base=master_uri)
                  master_rest = rip.RESTInPeace(conn)
      
                  # Now need to wait till cluster master exits maintenance mode
                  def not_in_maintenance_mode():
                      """
                      Check if the cluster master is in maintenance mode if yes
                      then wait or continue polling
                      """
                      info_content = json.loads(
                          master_rest.get_cluster_master(
                              id_name='info',
                              output_mode='json')[1])['entry'][0]['content']
                      self.logger.info("Cluster master info: {}".format(
                          info_content))
                      return (not info_content['maintenance_mode'] and
                              not info_content['rolling_restart_flag'] and
                              info_content['indexing_ready_flag'])
      
                  poll_for_condition(not_in_maintenance_mode)
      
                  # Once out of maintenance mode then we can check if each index is
                  # searchable
      
                  def is_index_searchable():
                      """
                      Check if each peer's status is now searchable.
      
                      @rtype: boolean
                      @rparam: Status of the peer is searchable.
                      """
                      peers = json.loads(
                          master_rest.get_cluster_master(
                              id_name='peers', output_mode='json')[1])
      
                      for peer in peers['entry']:
                          self.logger.info("Peer info: {}".format(peer))
                          if(peer['content']['status'] != 'Up' or
                                  not peer['content']['is_searchable']):
                              return False
                      return True
      
                  poll_for_condition(is_index_searchable)
      
          def setup(self):
              """
              Setup needed to perform for sending data.
              """
              pass
      
          def index_log(self):
              """
              Method to send data and perform indexing on that data.
              """
              pass
      
          def teardown(self):
              """
              Teardown the setup for indexing log
              """
              pass
      
          def get_current_event_count(
                  self, rest=None, poll_frequency=0.5, timeout=30):
              """
              Gets current event count during log indexing in order to wait for the
              expected event count.
      
              :type rest: RESTInPeace
              :param rest: the rest connection, using self.rest if not specified
      
              :type poll_frequency: number
              :param poll_frequency: frequency for checking the search job status
      
              :type timeout: int
              :param timeout: timeout to get current event count
      
              :rtype int
              :return current event count
              """
              rest = rest or self.rest
      
              src = (self.source.replace('\\\\', '\\\\\\\\')
                     if _platform == 'win32' else self.source)
              search_string = (
                  '| metadata type=sources index="{i}" | search source="{l}" '
                  '| appendcols [search index="{i}" source="{l}" | head 1 '
                  '| stats count as hasSearchableEvent]'.format(i=self.index, l=src))
      
              _, cont = rest.create_job(
                  search=search_string, output_mode='json')
              sid = json.loads(cont)[u'sid']
      
              def wait_for_job_done():
                  """
                  Wait for job to be done
                  """
                  job = json.loads(rest.get_job(sid, output_mode='json')[1])
                  return job['entry'][0]['content']['dispatchState'] == 'DONE'
      
              poll_for_condition(
                  wait_for_job_done,
                  frequency=poll_frequency, timeout=timeout,
                  error_message="Timeout during getting event count of "
                                "{log}".format(log=self.log_path))
      
              _, job_cont = rest.get_job(
                  sid, sub_endpoint='results', output_mode='json')
              results = json.loads(job_cont)['results']
      
              if bool(results):
                  total_count = int(json.loads(job_cont)['results'][0].get(
                      'totalCount', 0))
                  has_searchable_event = int(json.loads(job_cont)['results'][0].get(
                      'hasSearchableEvent', 0))
                  if has_searchable_event:
                      return total_count
                  else:
                      return 0
      
          def wait_for_event_count(self, rest=None, poll_frequency=0.5):
              """
              Wait for the expected event count
      
              :type rest: RESTInPeace
              :param rest: the rest connection, using the self one if not specified
      
              :type poll_frequency: number
              :param poll_frequency: frequency for checking
              """
              rest = rest or self.rest
      
              # polling wait to let the log be fully indexed
              poll_for_condition(
                  lambda: self.event_count <= self.get_current_event_count(rest),
                  frequency=poll_frequency, timeout=self.index_wait,
                  error_message='After {s} seconds, the file {f} is not completely '
                                'indexed.'.format(
                      s=self.index_wait, f=self.log_path))
      
              self.logger.info(
                  normalize_to_str('Log file {f} is completely indexed.'.format(
                      f=self.log_path)))
      
      
      class HttpInput(object):
      
          def __init__(self, host, port, token=None,
                       channel=None, ack=False, ssl=False):
      
              self._host = host
              self._port = port
              self._token = token
              self._is_ssl = ssl
              self._build_url()
              self._build_url_raw()
              self._build_url_ack()
              self._header = {}
              channel = channel or self._token
      
              if token:
                  self._header = {
                      'Authorization': 'Splunk {t}'.format(t=self._token)}
              if ack:
                  self._header['x-splunk-request-channel'] = channel
      
          def _build_url(self):
              self._url = "http{}://{}:{}/services/collector/event".format(
                  's' if self._is_ssl else '', self._host, self._port)
      
          def _build_url_raw(self):
              self._url_raw = "http{}://{}:{}/services/collector/raw".format(
                  's' if self._is_ssl else '', self._host, self._port)
      
          def _build_url_ack(self):
              self._url_ack = "http{}://{}:{}/services/collector/ack".format(
                  's' if self._is_ssl else '', self._host, self._port)
      
          def query_event_ack_status(self, ack_ids, user=None,
                                     pwd=None, verify=True):
              """
              Query event ack status
      
              :type ack_ids: str
              :param ack_ids: ack ids
      
              :type user: str
              :param user: splunk user
      
              :param pwd: str
              :param pwd: splunk password
      
              :type verify: bool
              :param verify: if need verify response status code
      
              :return: the response item
              :rtype: requests.Response
              """
      
              auth = HTTPDigestAuth(user, pwd) if user else None
              response = requests.post(
                  self._url_ack, headers=self._header,
                  data=ack_ids, verify=False, auth=auth)
              if verify:
                  if not response.ok:
                      raise HECRequestException(
                          'Failed to query event ack status via HTTP Input. \\n'
                          'status code:{status_code} \\n'
                          'response content: {cont}'.format(
                              status_code=response.status_code,
                              cont=response.content))
              return response
      
          def send(self, payload, raw=False, host=None, index=None, source=None,
                   sourcetype=None, time=None, fields=None, verify=True):
              """
              send data using HEC
      
              :param payload: the payload you want to send through hec
              :type payload: for raw=True, this is an object that will be
                             normalized to ascii str
                             for raw=False, this is an object that will be
                             json dumped
      
              :param raw: True means send using hec raw, False means send using event
              :type raw: bool
      
              :param host: host name
              :type host: str
      
              :param index: index name
              :type index: str
      
              :param source: user defined event source
              :type source: str
      
              :param sourcetype: user defined event sourcetype
              :type sourcetype: str
      
              :param time: epoch-formatted time
              :type time: str or unsigned integer
      
              :param fields: for raw=False only, fields for indexing that do not
                             occur in the event payload itself
              :type fields: dict
      
              :type verify: bool
              :param verify: if need verify response status code
      
              :return: the response item
              :rtype: requests.Response
              """
              params = {}
              if raw:
                  url = self._url_raw
                  data = normalize_to_str(payload)
              else:
                  url = self._url
                  data_dict = {'event': payload}
                  if fields is not None:
                      data_dict['fields'] = fields
                  data = json.dumps(data_dict)
      
              if host is not None:
                  params['host'] = host
              if index is not None:
                  params['index'] = index
              if source is not None:
                  params['source'] = source
              if sourcetype is not None:
                  params['sourcetype'] = sourcetype
              if time is not None:
                  params['time'] = time
      
              response = requests.post(
                  url, headers=self._header, data=data, verify=False, params=params)
              if verify:
                  if not response.ok:
                      raise HECRequestException(
                          'Failed to send data via HTTP Input. \\n'
                          'status code:{status_code} \\n'
                          'response content: {cont}'.format(
                              status_code=response.status_code,
                              cont=response.content))
              return response
      
      
      class HttpInputLog(IndexLog):
          """
          Class to index a log file via HTTP Input.
      
          """
      
          def __init__(
                  self, logfile_name, logfile_dir, sourcetype, event_count, index,
                  username, password, mgmt_url):
              """
              Initializes some class variables, that could be referenced later.
      
              @type logfile_name: string
              @param logfile_name: name of the log file
      
              @type logfile_dir: string
              @param logfile_dir: dir of the log file
      
              @type sourcetype: string
              @param sourcetype: name of sourcetype for the log file
      
              @type event_count: int
              @param event_count: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type username: string
              @param username: username of the admin user to make rest conn
      
              @type password: string
              @param password: password of the admin user to make rest conn
      
              @type mgmt_url: string
              @param mgmt_url: the splunkd managment url
      
              """
      
              self.token_name = '{s}_http_input'.format(s=sourcetype)
              source = 'http:{s}'.format(s=self.token_name)
      
              super(HttpInputLog, self).__init__(
                  logfile_name, logfile_dir, sourcetype, event_count, index,
                  source, username, password, mgmt_url)
      
              self.host = mgmt_url.split(':')[1].strip('//')
              self.port = 8088
      
              self.logger = logging.getLogger(self.__class__.__name__)
      
          def setup(self):
              self.rest.edit_http_input(
                  'http', enableSSL=False, port=self.port, disabled=False,
                  output_mode='json')
      
              self.rest.create_http_input(
                  name=self.token_name, sourcetype=self.sourcetype,
                  index=self.index, output_mode='json')
      
          def index_log(self):
              http_input_json = self.rest.get_http_input(
                  self.token_name, output_mode='json')[1]
              token = json.loads(http_input_json)['entry'][0]['content']['token']
              self.logger.info(
                  normalize_to_str('index log using token: {t}'.format(t=token)))
      
              http_input = HttpInput(host=self.host, port=self.port, token=token)
              with open(self.log_path) as log_file:
                  for line in log_file.readlines():
                      http_input.send(line)
      
          def teardown(self):
              if self.rest.check_http_input(self.token_name):
                  self.rest.delete_http_input(self.token_name)
      
      
      class OneshotInputLog(IndexLog):
          """
          Class to index once a log file for testing.
          """
          def __init__(
                  self, logfile_name, sourcetype, event_count, times=1, index='main',
                  logfile_dir=None, username=None, password=None, mgmt_url=None,
                  path_util=os.path, index_wait=INDEX_WAIT, rest_settings=None,
                  source=None):
              """
              Initializes some class variables, that could be referenced later.
      
              :type logfile_name: string
              :param logfile_name: name of the log file
      
              :type sourcetype: string
              :param sourcetype: name of sourcetype for the log file
      
              :type event_count: int
              :param event_count: number of events in the log file.
      
              :type times: int
              :param times: how many times of oneshot will be done
      
              :type index: string
              :param index: name of the index for the log file
      
              :type logfile_dir: string
              :param logfile_dir: dir of the log file
      
              :type username: string
              :param username: username of the admin user to make rest conn
      
              :type password: string
              :param password: password of the admin user to make rest conn
      
              :type mgmt_url: string
              :param mgmt_url: the splunkd managment url
      
              :type path_util: object
              :param path_util: the file path util
      
              :type index_wait: int
              :param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
      
              """
              if logfile_dir is None:
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              if not path_util.exists(log_path):
                  raise FileNotFound(
                      "Could not locate the file '{}'.".format(log_path))
      
              if source is None:
                  source = log_path
      
              super(OneshotInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count * times, index=index,
                  logfile_dir=logfile_dir, username=username, password=password,
                  source=source, mgmt_url=mgmt_url, path_util=path_util,
                  index_wait=index_wait, rest_settings=rest_settings)
              self.times = times
      
          def index_log(self, rest=None):
              # TODO remove rest param,  currently only used by
              # theatre/puppets/indexer.py: log_object.index_log(self.nobody_rest)
              rest = rest or self.rest
              self.logger.info(normalize_to_str(
                  "Editing indexer rest settings: {}".format(self.rest_settings)))
              try:
                  for endpoint, params in self.rest_settings.iteritems():
                      self.set_rest_setting(endpoint, params, rest)
              except Exception as err:
                  self.logger.warn(normalize_to_str(
                      "Failed to setup the index for the log file. "
                      "Tests may possibly fail. {e}".format(e=err)))
      
              for _ in range(self.times):
                  rest.create_input_oneshot(
                      output_mode='json', name=self.log_path,
                      index=self.index, sourcetype=self.sourcetype,
                      **{'rename-source': self.source})
      
      
      class MonitorInputLog(IndexLog):
          """
          Class to use for monitoring a log file for testing.
      
          """
          def __init__(
                  self, logfile_name, sourcetype, event_count, index='main',
                  logfile_dir=None, username=None, password=None, mgmt_url=None,
                  path_util=os.path, index_wait=INDEX_WAIT, rest_settings=None):
      
              """
              Initializes some class variables, that could be referenced later.
      
              @type logfile_name: string
              @param logfile_name: name of the log file
      
              @type sourcetype: string
              @param sourcetype: name of sourcetype for the log file
      
              @type event_count: int
              @param event_count: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type logfile_dir: string
              @param logfile_dir: dir of the log file
      
              @type username: string
              @param username: username of the admin user to make rest conn
      
              @type password: string
              @param password: password of the admin user to make rest conn
      
              @type mgmt_url: string
              @param mgmt_url: the splunkd managment url
      
              @type path_util: object
              @param path_util: the file path util
      
              @type index_wait: int
              @param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
      
              """
              if logfile_dir is None:
                  # attempt to look at relative src path.
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              super(MonitorInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=logfile_dir, username=username, password=password,
                  source=log_path, mgmt_url=mgmt_url, path_util=path_util,
                  index_wait=index_wait, rest_settings=rest_settings)
      
              self.logger = logging.getLogger(self.__class__.__name__)
      
          def index_log(self, fwd_rest=None, idx_rest=None):
              """
              Setting up forwarder to index data to the indexer provided
      
              @type fwd_rest RESTInPeace
              @param fwd_rest the rest connection, using the self if not specified
      
              @type idx_rest RESTInPeace
              @param idx_rest the rest connection, using the self if not specified
      
              """
              fwd_rest = fwd_rest or self.fwd_rest
              idx_rest = idx_rest or self.rest
              self.logger.info(normalize_to_str(
                  "Editing indexer rest settings: {}".format(self.rest_settings)))
              try:
                  for endpoint, params in self.rest_settings.iteritems():
                      self.set_rest_setting(endpoint, params, idx_rest)
                  self.logger.info(normalize_to_str(
                      "Monitoring the file: {f}".format(f=self.log_path)))
                  fwd_rest.create_input_monitor(
                      name=self.log_path, sourcetype=self.sourcetype,
                      index=self.index)
                  self.logger.info(
                      "Index log {l} on index {i} with sourcetype {s}".format(
                          l=self.log_path, i=self.index, s=self.sourcetype))
                  fwd_rest.wait_for_input_monitor_to_be_created(self.log_path)
      
              except Exception as err:
                  self.logger.warn(normalize_to_str(
                      "Failed to setup the index for the log file. "
                      "Tests may possibly fail. {e}".format(e=err)))
      
          def teardown(self):
              self.logger.info(normalize_to_str('Delete input monitor if necessary'))
              if self.rest.check_input_monitor(self.log_path):
                  self.rest.delete_input_monitor(self.log_path)
                  self.rest.wait_for_input_monitor_to_be_deleted(self.log_path)
      
      
      class ForwarderInputLog(IndexLog):
          """
          Class to use local splunk to monitor log and forward data to remote server.
          It will be deprecated in later. Use ForwardingInputLog instead.
          """
      
          def __init__(
                  self, logfile_name, sourcetype, event_count, index,
                  receiver_host, receiver_port,
                  receiver_username, receiver_password, receiver_mgmt_url,
                  fwd_username=None, fwd_password=None, fwd_mgmt_url=None,
                  path_util=os.path, index_wait=480, rest_settings=None,
                  data_path=None):
              """
              Initializes some class variables, that could be referenced later.
      
              @type logfile_name: string
              @param logfile_name: name of the log file
      
              @type sourcetype: string
              @param sourcetype: name of sourcetype for the log file
      
              @type event_count: int
              @param event_count: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type receiver_host: string
              @param receiver_host: hostname of the receiver
      
              @type receiver_port: string
              @param receiver_port: port number of receiveiver ready to receive
      
              @type receiver_username: string
              @param receiver_username: username of the receiver to make rest conn
      
              @type receiver_password: string
              @param receiver_password: password of the receiver to make rest conn
      
              @type receiver_mgmt_url: string
              @param receiver_mgmt_url: splunkd url of receiver
      
              @type fwd_username: string
              @param fwd_username: username of the forwarder to make rest conn
      
              @type fwd_password: string
              @param fwd_password: password of the forwarder to make rest conn
      
              @type fwd_mgmt_url: string
              @param fwd_mgmt_url: the forwarder managment url
      
              @type index_wait: int
              @param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
      
              """
      
              self.monitor_input_log = MonitorInputLog(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index, logfile_dir=data_path,
                  username=fwd_username, password=fwd_password,
                  mgmt_url=fwd_mgmt_url, path_util=path_util,
                  index_wait=index_wait, rest_settings=rest_settings)
      
              super(ForwarderInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=self.monitor_input_log.logfile_dir,
                  username=self.monitor_input_log.username,
                  password=self.monitor_input_log.password,
                  source=self.monitor_input_log.log_path,
                  mgmt_url=self.monitor_input_log.mgmt_url,
                  index_wait=index_wait, rest_settings=rest_settings)
      
              self.tcp_input_name = str(receiver_port)
              self.tcp_output_server = '{h}:{p}'.format(
                  h=receiver_host, p=receiver_port)
      
              receiver_conn = rip.RESTConnectorReplacement(
                  username=receiver_username, password=receiver_password,
                  app='search', uri_base=receiver_mgmt_url)
              self.receiver_rest = rip.RESTInPeace(receiver_conn)
              self.sourcetype_name = sourcetype
              self.logger = logging.getLogger(self.__class__.__name__)
      
          def setup(self):
              """
              Sets up input monitor on the indexer side and output monitor on
              forwarder side
              """
              self.monitor_input_log.setup()
              self.receiver_rest.create_input_tcp_cooked(
                  name=self.tcp_input_name)
              self.receiver_rest.wait_for_input_tcp_cooked_to_be_created(
                  self.tcp_input_name)
      
              self.fwd_rest.create_tcp_output_server(name=self.tcp_output_server)
              self.fwd_rest.wait_for_tcp_output_server_to_be_created(
                  self.tcp_output_server)
      
          def index_log(self):
              """
              Override the index_log function of super to pass in forwarder and
              receiver's rest object to monitor data.
              """
              self.monitor_input_log.index_log(
                  fwd_rest=self.fwd_rest, idx_rest=self.receiver_rest)
      
          def wait_for_event_count(self):
              """
              Override the super method to wait for event count at receiver/indexer
              end
              """
              self.monitor_input_log.wait_for_event_count(self.receiver_rest)
      
          def get_current_event_count(self):
              """
              Override the super method to get count of log indexed.
      
              :return:
              """
              return self.monitor_input_log.get_current_event_count(
                  self.receiver_rest)
      
          def teardown(self):
              """
              Delete the setup done at forwarder and receiver side
      
              On forwarder side, delete the tcp_output_server
              On receiver side, delete the tcp_input server
              """
              try:
                  if (hasattr(pytest.config, 'instance_type')
                          and pytest.config.instance_type != 'cloud'):
                      self.logger.info(
                          normalize_to_str('Delete tcp output server if necessary'))
                      if self.fwd_rest.check_tcp_output_server(
                              self.tcp_output_server):
                          self.fwd_rest.delete_tcp_output_server(
                              self.tcp_output_server)
                          self.fwd_rest.wait_for_tcp_output_server_to_be_deleted(
                              self.tcp_output_server)
      
                      self.logger.info(
                          normalize_to_str('Delete tcp input if necessary'))
                      if self.receiver_rest.check_input_tcp_cooked(
                              self.tcp_input_name):
                          self.receiver_rest.delete_input_tcp_cooked(
                              self.tcp_input_name)
                          self.receiver_rest.wait_for_input_tcp_cooked_to_be_deleted(
                              self.tcp_input_name)
              finally:
                  self.monitor_input_log.teardown()
      
          def monitor(self):
              """
              Method for sending and indexing the log file.
              """
              if pytest.config.instance_type != 'cloud':
                  self.setup()
              self.index_log()
              self.wait_for_event_count()
      
          def remove_monitor(self):
              """
              Remove the monitor
              """
              self.teardown()
      
      
      class MonitorLog(MonitorInputLog):
      
          """
          Class to use for monitoring a log file for testing.
          For backwards compatibility
          """
      
          def __init__(
                  self,
                  name,
                  srctype,
                  evtcnt,
                  index='main',
                  data_path=None,
                  username=None,
                  password=None,
                  index_wait=INDEX_WAIT,
                  rest_settings=None):
              """
              Initializes some class variables, that could be referenced later.
      
              @type name: string
              @param name: name of the log file
      
              @type srctype: string
              @param srctype: name of sourcetype for the log file
      
              @type evtcnt: int
              @param evtcnt: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type data_path: string
              @param data_path: name of the log file
      
              @type mgmt_url: string
              @param mgmt_url: the splunk managment url
      
              @type path_util: object
              @param path_util: the file path util
      
              @type index_wait: int
              @param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
      
              """
              super(MonitorLog, self).__init__(
                  logfile_name=name, sourcetype=srctype,
                  event_count=evtcnt, index=index,
                  logfile_dir=data_path, username=username, password=password,
                  index_wait=index_wait, rest_settings=rest_settings)
      
              self.sourcetype_name = srctype
              self.logger = logging.getLogger(self.__class__.__name__)
      
          def monitor(self):
              self.index_log()
              self.wait_for_event_count()
      
          def remove_monitor(self):
              """
              Remove the monitor
              """
              self.teardown()
      
      
      class StreamingInputLog(IndexLog):
          """
          Class to use for uploading a log file for testing.
          """
      
          def __init__(
                  self, logfile_name, sourcetype, event_count, index='main',
                  logfile_dir=None, username=None, password=None, mgmt_url=None,
                  path_util=os.path, index_wait=INDEX_WAIT, rest_settings=None):
              """
              StreamingInputLog Init
      
              :type logfile_name: string
              :param logfile_name: name of the log file
      
              :type sourcetype: string
              :param sourcetype: name of sourcetype for the log file
      
              :type event_count: int
              :param event_count: number of events in the log file.
      
              :type index: string
              :param index: name of the index for the log file
      
              :type logfile_dir: string
              :param logfile_dir: dir of the log file
      
              :type username: string
              :param username: splunk username
      
              :type password: string
              :param password: splunk password
      
              :type mgmt_url: string
              :param mgmt_url: the splunk management url
      
              :type path_util: object
              :param path_util: the file path util
      
              :type index_wait: int
              :param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              :type rest_settings: dict
              :param rest_settings: rest settings
              """
      
              if logfile_dir is None:
                  # attempt to look at relative src path.
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              # prevent splunk handling the compressed file using build-in logic
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              if (tarfile.is_tarfile(log_path) or zipfile.is_zipfile(log_path) or
                      self.is_gz_file(log_path) or
                      (bz2 is not None and self.is_bz2_file(log_path))):
                  log_path += ".extracted"
      
              super(StreamingInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=logfile_dir, username=username, password=password,
                  source=log_path, mgmt_url=mgmt_url,
                  path_util=path_util,
                  index_wait=index_wait, rest_settings=rest_settings)
              # for legacy test cases
              self.sourcetype_name = sourcetype
      
          @staticmethod
          def is_gz_file(name):
              """
              judge file type whether is gz with given file name
              :param name: the file name
              :type name: string
              :rtype: bool
              :return: if it is gz file type, then return True else False
              """
              with open(name, 'rb') as file:
                  return binascii.hexlify(file.read(2)) == b'1f8b'
      
          @staticmethod
          def is_bz2_file(name):
              """
              judge file type whether is bz2 with given file name
              :param name: the file name
              :type name: string
              :rtype: bool
              :return: if it is bz2 file type, then return True else False
              """
              with open(name, 'rb') as file:
                  return binascii.hexlify(file.read(2)) == b'425a'
      
          def index_log(self):
              """
              Index log by streaming
              """
              parsed_mgmt_url = urlparse.urlparse(self.mgmt_url)
      
              if hasattr(ssl, 'SSLContext'):
                  ssl_context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
                  conn = httplib.HTTPSConnection(
                      parsed_mgmt_url.hostname, parsed_mgmt_url.port,
                      context=ssl_context)
              else:
                  conn = httplib.HTTPSConnection(
                      parsed_mgmt_url.hostname, parsed_mgmt_url.port)
      
              conn.connect()
      
              def sent_plain_data_in_dir(dir_name):
                  """
                  read plain data in dir and sent data
                  :type dir_name: string
                  :param dir_name: the absolute path of the directory
                  """
                  for file_name in os.listdir(dir_name):
                      file_path = os.path.join(dir_name, file_name)
                      if os.path.isdir(file_path):
                          sent_plain_data_in_dir(file_path)
                      else:
                          with open(file_path) as f:
                              line = f.readline()
                              while line:
                                  conn.send(line)
                                  line = f.readline()
      
              def send_data(name):
                  """
                  send data stream to splunk, supports plain text, tar file and
                   compressed file type zip, gz and bz2
                  :param name: the given file name
                  :type name: string
                  """
                  try:
                      if tarfile.is_tarfile(name):
                          tempdir = tempfile.mkdtemp()
                          with tarfile.open(name) as tf:
                              tf.extractall(tempdir)
                          sent_plain_data_in_dir(tempdir)
      
                      elif zipfile.is_zipfile(name):
                          tempdir = tempfile.mkdtemp()
                          with zipfile.ZipFile(name, 'r') as zip_file:
                              zip_file.extractall(tempdir)
                          sent_plain_data_in_dir(tempdir)
      
                      elif self.is_gz_file(name):
                          with gzip.open(name, 'rb') as f:
                              line = f.readline()
                              while line:
                                  conn.send(line)
                                  line = f.readline()
      
                      elif bz2 is not None and self.is_bz2_file(name):
                          with bz2.BZ2File(name, 'rb') as f:
                              line = f.readline()
                              while line:
                                  conn.send(line)
                                  line = f.readline()
      
                      else:
                          with open(name) as f:
                              line = f.readline()
                              while line:
                                  conn.send(line)
                                  line = f.readline()
                  except IOError as ex:
                      self.logger.error('io error occurs', exc_info=True)
                      raise ex
      
              try:
                  url_args = {
                      'index': self.index,
                      'source': self.source,
                      'sourcetype': self.sourcetype}
                  url_params = urllib.urlencode(url_args)
      
                  stream_uri = '/services/receivers/stream?{}'.format(url_params)
                  self.logger.info('stream_uri: {}'.format(stream_uri))
                  conn.putrequest('POST', stream_uri)
      
                  auth = '{u}:{p}'.format(u=self.username, p=self.password)
                  self.logger.info('stream_auth: {}'.format(auth))
                  conn.putheader('Authorization', 'Basic {}'.format(b64encode(auth)))
                  conn.putheader('x-splunk-input-mode', 'streaming')
                  conn.endheaders()
      
                  send_data(self.log_path)
              finally:
                  conn.close()
      
      
      class ForwardingInputLog(IndexLog):
          """
          use Splunk forwarder to monitor log and forward data to remote servers
          """
          def __init__(
                  self, logfile_name, sourcetype, event_count, index,
                  receiver_port, receivers,
                  fwd_username=None, fwd_password=None, fwd_mgmt_url=None,
                  path_util=os.path, index_wait=480, rest_settings=None,
                  logfile_dir=None):
              """
              Initializes some class variables, that could be referenced later.
      
              :type logfile_name: string
              :param logfile_name: name of the log file
      
              :type sourcetype: string
              :param sourcetype: name of sourcetype for the log file
      
              :type event_count: int
              :param event_count: number of events in the log file.
      
              :type index: string
              :param index: name of the index for the log file
      
              :type receiver_port: int
              :param receiver_port: port number of receiver ready to receive
      
              :type receivers: list of puppet
              :param receivers: receivers of forwarding data. For example,
              get theatre deployment stage, receivers=stage.indexers.all(), all
              indexers in the deployment will be the receivers of forwarding data.
      
              :type fwd_username: string
              :param fwd_username: username of the forwarder to make rest conn
      
              :type fwd_password: string
              :param fwd_password: password of the forwarder to make rest conn
      
              :type fwd_mgmt_url: string
              :param fwd_mgmt_url: the forwarder management url
      
              :type index_wait: int
              :param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              :type rest_settings: dict
              :param rest_settings: rest settings
      
              """
              self.logger = logging.getLogger(self.__class__.__name__)
      
              if logfile_dir is None:
                  # attempt to look at relative src path.
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              super(ForwardingInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=logfile_dir,
                  username=fwd_username,
                  password=fwd_password,
                  source=log_path,
                  mgmt_url=fwd_mgmt_url,
                  index_wait=index_wait, rest_settings=rest_settings)
              # for legacy test cases
              self.sourcetype_name = sourcetype
              self.receivers = receivers
              self.tcp_input_name = str(receiver_port)
              self.tcp_output_group = 'search_peers_group'
      
          def setup(self):
              """
              Sets up input monitor on the indexer side and output monitor on
              forwarder side
              """
              for receiver in self.receivers:
                  with receiver.rest.namespace('nobody', 'system'):
                      receiver.rest.create_input_tcp_cooked(
                          name=self.tcp_input_name, output_mode='json')
                      receiver.rest.wait_for_input_tcp_cooked_to_be_created(
                          self.tcp_input_name)
      
              my_search_peers = [
                  '{h}:{p}'.format(
                      h=receiver.splunk.splunkd_host(),
                      p=self.tcp_input_name) for receiver in self.receivers]
      
              self.fwd_rest.create_tcp_output_group(
                  output_mode='json',
                  **{'name': self.tcp_output_group,
                     'servers': ','.join(my_search_peers)})
      
          def index_log(self):
              """
              Monitor data on forwarder
              """
              self.logger.info(normalize_to_str(
                  "Editing indexer rest settings: {}".format(self.rest_settings)))
              try:
                  self.logger.info(normalize_to_str(
                      "Monitoring the file: {f}".format(f=self.log_path)))
                  self.fwd_rest.create_input_monitor(
                      name=self.log_path, sourcetype=self.sourcetype,
                      index=self.index)
                  self.logger.info(
                      "Index log {l} on index {i} with sourcetype {s}".format(
                          l=self.log_path, i=self.index, s=self.sourcetype))
                  self.fwd_rest.wait_for_input_monitor_to_be_created(self.log_path)
      
              except Exception as err:
                  self.logger.warn(normalize_to_str(
                      "Failed to setup the index for the log file. "
                      "Tests may possibly fail. {e}".format(e=err)))
      
          def teardown(self):
              """
              Delete the setup done at forwarder and receiver side
      
              On forwarder side, delete the input monitor and tcp_output_server
              On receiver side, delete the tcp_input server
              """
              self.logger.info(
                  normalize_to_str('Delete input monitor if necessary'))
              if self.fwd_rest.check_input_monitor(self.log_path):
                  self.fwd_rest.delete_input_monitor(self.log_path)
                  self.fwd_rest.wait_for_input_monitor_to_be_deleted(self.log_path)
      
              self.logger.info(
                  normalize_to_str('Delete tcp output server if necessary'))
      
              if self.fwd_rest.check_tcp_output_group(
                      self.tcp_output_group):
                  self.fwd_rest.delete_tcp_output_group(
                      self.tcp_output_group)
                  self.fwd_rest.wait_for_tcp_output_group_to_be_deleted(
                      self.tcp_output_group)
      
              self.logger.info(
                  normalize_to_str('Delete tcp input if necessary'))
              input_name = self.tcp_input_name
              for receiver in self.receivers:
                  with receiver.rest.namespace('nobody', 'system'):
                      rest = receiver.rest
                      if rest.check_input_tcp_cooked(input_name):
                          rest.delete_input_tcp_cooked(input_name)
                          rest.wait_for_input_tcp_cooked_to_be_deleted(
                              input_name)
      
      
      class CloudForwardingInputLog(IndexLog):
          """
          use Splunk forwarder to monitor log and forward data to remote servers in
          cloud deployment
          """
          def __init__(
                  self, logfile_name, sourcetype, event_count, index,
                  fwd_username=None, fwd_password=None, fwd_mgmt_url=None,
                  path_util=os.path, index_wait=480, rest_settings=None,
                  logfile_dir=None):
              """
              CloudForwardingInputLog Init
      
              :type logfile_name: string
              :param logfile_name: name of the log file
      
              :type sourcetype: string
              :param sourcetype: name of sourcetype for the log file
      
              :type event_count: int
              :param event_count: number of events in the log file.
      
              :type index: string
              :param index: name of the index for the log file
      
              :type fwd_username: string
              :param fwd_username: username of the forwarder to make rest conn
      
              :type fwd_password: string
              :param fwd_password: password of the forwarder to make rest conn
      
              :type fwd_mgmt_url: string
              :param fwd_mgmt_url: the forwarder management url
      
              :type index_wait: int
              :param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              :type rest_settings: dict
              :param rest_settings: rest settings
      
              """
              self.logger = logging.getLogger(self.__class__.__name__)
      
              if logfile_dir is None:
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              super(CloudForwardingInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=logfile_dir,
                  username=fwd_username,
                  password=fwd_password,
                  source=log_path,
                  mgmt_url=fwd_mgmt_url,
                  index_wait=index_wait, rest_settings=rest_settings)
              # for legacy test cases
              self.sourcetype_name = sourcetype
      
          def index_log(self):
              """
              Monitor data on forwarder
              """
              self.logger.info(normalize_to_str(
                  "Editing forwarder rest settings: {}".format(self.rest_settings)))
              try:
                  self.logger.info(normalize_to_str(
                      "Monitoring the file: {f}".format(f=self.log_path)))
                  self.rest.create_input_monitor(
                      name=self.log_path, sourcetype=self.sourcetype,
                      index=self.index)
                  self.logger.info(
                      "Index log {l} on index {i} with sourcetype {s}".format(
                          l=self.log_path, i=self.index, s=self.sourcetype))
                  self.rest.wait_for_input_monitor_to_be_created(self.log_path)
      
              except Exception as err:
                  self.logger.warn(normalize_to_str(
                      "Failed to setup the index for the log file. "
                      "Tests may possibly fail. {e}".format(e=err)))
      
          def teardown(self):
              """
              Delete the setup done at forwarder side
              """
              self.logger.info(
                  normalize_to_str('Delete input monitor if necessary'))
              if self.rest.check_input_monitor(self.log_path):
                  self.rest.delete_input_monitor(self.log_path)
                  self.rest.wait_for_input_monitor_to_be_deleted(self.log_path)
      
    '''
  }
  {
    name: ""
    mode: "Python"
    content: '''
      #!/usr/bin/python
      # vim: set fileencoding=utf-8 :
      
      import errno
      import json
      import logging
      from socket import gethostbyname
      
      import re
      import os
      import copy
      import httplib
      import socket
      import rip
      import contextlib
      import urllib
      from sharedtestutils.MethodMissing import MethodMissing
      from sharedtestutils.decorators import deprecated
      from sharedtestutils.decorators import deprecated_by
      
      from ..puppeteers import Puppeteer
      from ..utils.monitorlog import HttpInput
      
      
      TRUE_VALUES = (True, 't', 'true', '1', 1)
      
      
      class SimpleSplunk(object):
          """
          The Simple Splunk for REST-only splunk instance
          """
      
          def __init__(
                  self, web_host='localhost', splunkd_host='localhost',
                  web_port='8000', splunkd_port='8089',
                  username='admin', password='changeme', name=None):
              """
              SimpleSplunk init
      
              :param web_host: the specified splunkweb host
              :param splunkd_host: the specified splunkd host
              :param web_port: the specified splunkweb port
              :param splunkd_port: the specified splunkd port
              :param username: the specified splunk username
              :param password: the specified splunk password
              :param name: the specified instance name
              """
              self._web_host = web_host
              self._splunkd_host = splunkd_host
              self._web_port = web_port
              self._splunkd_port = splunkd_port
              self._username = username
              self._password = password
              self._name = name or splunkd_host
      
          def web_host(self):
              """
              Gets splunkweb host
      
              :rtype: str
              :return: splunkweb host
              """
              return self._web_host
      
          def splunkd_host(self):
              """
              Gets splunkd host
      
              :rtype: str
              :return: splunkd host
              """
              return self._splunkd_host
      
          def web_port(self):
              """
              Gets splunkweb port
      
              :rtype: int
              :return: splunkweb port
              """
              return self._web_port
      
          def splunkd_port(self):
              """
              Gets splunkd port
      
              :rtype: int
              :return: splunkd port
              """
              return self._splunkd_port
      
          def uri_base(self):
              """
              Gets splunkd uri base
      
              :rtype: str
              :return: splunkd uri base
              """
              return 'https://{h}:{p}'.format(
                  h=self.splunkd_host(), p=self.splunkd_port())
      
          @property
          def username(self):
              """
              Gets splunk username
      
              :rtype: str
              :return: splunk username
              """
              return self._username
      
          @property
          def password(self):
              """
              Gets splunk password
      
              :rtype: str
              :return: splunk password
              """
              return self._password
      
          @property
          def name(self):
              """
              Gets splunk name
      
              :rtype: str
              :return: splunk name
              """
              return self._name
      
          @property
          def splunk_home(self):
              """
              Gets splunk home
      
              :rtype: str
              :return: splunk home
              """
              return None
      
      
      class PuppetStatus(object):
          """
          Puppet status enum
          """
          RUNNING = 1
          STOPPED = 2
      
      
      class BasePuppet(MethodMissing):
          """
          Base class for puppet, which represents one instance in splunk deployment
          """
      
          def __init__(self):
              """
              BasePuppet Init
              """
              super(BasePuppet, self).__init__()
              self.logger = logging.getLogger(self.__class__.__name__)
      
          @property
          def status(self):
              """
              Returns the puppet status
              """
              raise NotImplementedError
      
      
      class SplunkPuppet(BasePuppet):
          """
          Puppet manages one splunk instance
          """
      
          def __init__(self, splunk):
              """
              SplunkPuppet init
      
              :type splunk: Splunk
              :param splunk: the specified splunk instance
              """
              super(SplunkPuppet, self).__init__()
              self._splunk = splunk
              self._init_rest()
              self.logger = logging.getLogger(self.__class__.__name__)
      
          @property
          @deprecated
          def splunk(self):
              """
              Gets the wrapped splunk instance
              """
              return self._splunk
      
          @property
          def fileutils(self):
              """
              Gets the splunk fileutils
              """
              return self._splunk.fileutils
      
          @property
          def splunk_home(self):
              """
              Gets the splunk home
      
              :rtype: str
              :return: splunk home
              """
              return self._splunk.splunk_home
      
          @property
          def username(self):
              """
              Gets splunk username
      
              :rtype: str
              :return: splunk username
              """
              return self._splunk.username
      
          @property
          def password(self):
              """
              Gets splunk password
      
              :rtype: str
              :return: splunk password
              """
              return self._splunk.password
      
          def splunkd_host(self):
              """
              Gets splunkd host
      
              :rtype: str
              :return: splunkd host
              """
              return self._splunk.splunkd_host()
      
          def splunkd_port(self):
              """
              Gets splunkd port
      
              :rtype: int
              :return: splunkd port
              """
              return self._splunk.splunkd_port()
      
          def splunkd_scheme(self):
              """
              Gets splunkd scheme
      
              :rtype: str
              :return: The splunkd scheme
              """
              return 'https' if self._is_splunkd_ssl_enabled() else 'http'
      
          def web_host(self):
              """
              Gets web host
      
              :rtype: str
              :return: web host
              """
              return self._splunk.web_host()
      
          def web_port(self):
              """
              Gets web port
      
              :rtype: int
              :return: web port
              """
              return self._splunk.web_port()
      
          def web_scheme(self):
              """
              Gets splunkweb scheme
      
              :rtype: str
              :return: The splunkweb scheme
              """
              return 'https' if self._is_web_ssl_enabled() else 'http'
      
          def _init_rest(self):
              """
              Init rest
              """
              conn = rip.RESTConnectorReplacement(
                  username=self.username, password=self.password,
                  uri_base=self.uri_base())
      
              self.rest = rip.RESTInPeace(conn)
      
          @property
          @deprecated
          def nobody_rest(self):
              """
              Gets nobody rest with system namespace
              """
              self.rest.change_namespace('nobody', 'system')
              return self.rest
      
          def token_rest(self, token):
              """
              Get rest with token
              """
              conn = rip.RESTConnectorReplacement(
                  username=self.username,
                  password=self.password,
                  uri_base=self.uri_base(),
                  token=token)
              return rip.RESTInPeace(conn)
      
          def get_http_input(self, token, port='8088',
                             channel=None, ack=False, ssl=False):
              """
              Get http event collector object
      
              :param token: http event collector token
              :type token: str
      
              :param port: http event collector port number
              :type port: str
      
              :param ack: should use ack
              :type ack: bool
      
              :param ssl: should use ssl
              :type ssl: bool
      
              :param channel: channel used for http input
              :type channel: str
      
              :return: http event collector object
              :rtype: HttpInput
              """
              return HttpInput(
                  host=self.web_host(),
                  port=port,
                  token=token,
                  channel=channel,
                  ack=ack,
                  ssl=ssl)
      
          def uri_base(self, scheme=True, use_server_name=False):
              """
              Gets splunk uri base url
      
              :param scheme: if true, result contains the uri scheme
                             if false, only the raw uri will be returned
              :type scheme: bool
      
              :param use_server_name: use host name but not ip
                                      if set this value as True
              :type use_server_name: bool
      
              :return: the uri base
              :rtype: str
              """
              if use_server_name:
                  _uri_base = '{scheme}://{host}:{web_port}'.format(
                      scheme=self.splunkd_scheme(),
                      host=self.server_name,
                      web_port=self.splunkd_port())
              else:
                  _uri_base = self._splunk.uri_base()
      
              if not scheme:
                  _uri_base = re.sub("http.?://", "", _uri_base)
      
              return _uri_base
      
          def web_base(self):
              """
              Gets splunk web base url
              """
              root_endpoint = self._get_root_endpoint()
              web_base = "{scheme}://{host}:{web_port}{end_point}".format(
                  scheme=self.web_scheme(), host=self.web_host(),
                  web_port=self.web_port(),
                  end_point=root_endpoint if root_endpoint != '/' else '')
              return web_base
      
          def _get_root_endpoint(self):
              """
              Gets root endpoint in settings.
              """
              return self.rest.get_property('web', 'settings/root_endpoint')[1]
      
          def _is_web_ssl_enabled(self):
              """
              Return True if splunk web ssl is enabled
              """
              result = self.rest.get_property(
                  'web', 'settings/enableSplunkWebSSL')[1]
              return result.lower() in TRUE_VALUES
      
          def _is_splunkd_ssl_enabled(self):
              """
              Return True if splunkd ssl is enabled
              """
              result = self.rest.get_property(
                  'server', 'sslConfig/enableSplunkdSSL')[1]
              return result.lower() in TRUE_VALUES
      
          def restart(self, timeout=360, use_rest=True):
              """
              Restart splunk instance
              :param use_rest: Restart Splunk via REST or not, default is True.
              :param timeout: REST restart time
              """
              if use_rest:
                  self.rest.restart(timeout=timeout)
                  if hasattr(self.splunk, '_splunk_has_started'):
                      self.splunk._splunk_has_started()
              else:
                  # Restart Splunk by native way rather than REST.
                  # If no 'self.splunk.restart()' then fallback restart via REST
                  try:
                      self.splunk.restart()
                  except AttributeError:
                      self.rest.restart(timeout=timeout)
              self._init_rest()
      
          def start(self, **kwargs):
              """
              Start splunk instance
              """
              self._splunk.start(**kwargs)
              self._init_rest()
      
          def stop(self):
              """
              Stop splunk instance
              """
              self._splunk.stop()
      
          @property
          def name(self):
              """
              Gets splunk name
              """
              return self._splunk.name
      
          @property
          def connection(self):
              """
              Gets the ssh connection that is used
      
              :rtype: SSHConnection
              :return: ssh connection
              """
              return self._splunk.connection
      
          def is_local(self):
              """
              Check if the splunk is local instance
              """
              return self.splunkd_host() in ['localhost', '127.0.0.1', '::1']
      
          def is_running(self):
              """
              Check if the splunk is running
              """
              try:
                  with self.rest.namespace('nobody', 'system'):
                      resp = self.rest.run_info(output_mode='json')[0]['status']
                      if int(resp) in self.rest.SUCCESS_CODES:
                          return True
                      else:
                          self.logger.warn(
                              'Splunkd is accessible but we are unable to '
                              'successfully get the server info.')
                          return False
              except (socket.error, httplib.HTTPException) as err:
                  self.logger.warn('[socket, http exception]Failed to check if'
                                   ' splunk is running: {}'.format(err))
                  return False
              except Exception as err:
      
                  # handle expected errors to be False and raise everything else
                  if getattr(err, 'errno', None) in [errno.ECONNREFUSED,
                                                     errno.EHOSTDOWN,
                                                     errno.ECONNRESET]:
                      self.logger.warn(
                          'Failed to check if splunk is running: {e}'.format(e=err))
                      return False
                  raise
      
          @property
          def status(self):
              """
              Returns the status of the splunk
              :rtype: PuppetStatus
              """
              return (PuppetStatus.RUNNING if self.is_running()
                      else PuppetStatus.STOPPED)
      
          @property
          def version(self):
              """
              Gets splunk version
      
              :rtype: str
              :return: splunk version
              """
              server_info = self.server_info
              return 'Splunk {t} {v} (build {b})'.format(
                  t=server_info['product_type'],
                  v=server_info['version'],
                  b=server_info['build'])
      
          @property
          @deprecated_by('server_info')
          def info_content(self):
              """
              Gets the server info
      
              :rtype: dict
              :return: server info dict
              """
              return self.server_info
      
          @property
          def server_info(self):
              """
              Gets the server info
      
              :rtype: dict
              :return: server info dict
                       return empty dict if is not running
              """
              if self.is_running():
                  with self.rest.namespace('nobody', 'system'):
                      return json.loads(
                          self.rest.run_info(
                              output_mode='json')[1])['entry'][0]['content']
              else:
                  return {}
      
          def has_server_role(self, server_role):
              """
              Check if the puppet has the specified server role.
      
              :type server_role: str
              :param server_role: the specified server role to check
      
              :rtype: bool
              :return: True if the puppet has the specified server role
              """
              server_info = self.server_info
              return ('server_roles' in server_info and
                      server_role in server_info['server_roles'])
      
          @property
          def host_os(self):
              \'''
              Gets the host OS, e.g. 'Linux', 'Windows', or 'Darwin'.
      
              :return: Operating System of the host machine
              :rtype: string
              \'''
              host_os = self._splunk.get_host_os()
              # in windows orca env, os type returned is cygwin_nt-10.0-14393, which
              # is returned by helmut, work it around with the fix.
              if 'cygwin_nt' in host_os.lower():
                  return 'Windows'
              return host_os
      
          @property
          def host_ip(self):
              \'''
              Gets the ip address of the machine hosting this puppet
              \'''
              return gethostbyname(self._splunk.splunkd_host())
      
          @property
          def host_arch(self):
              \'''
              Get the host architecture
      
              :return: architecture of the host machine (64 bit/ 32 bit)
              :rtype: string
              \'''
              return self._splunk.get_host_platform()
      
          def is_remote_login_enabled(self):
              """
              Check if remote login is enabled.
              7.1+ behavior is not changed due to SPL-160369
              """
              try:
                  value = self.nobody_rest.get_property(
                      "server", "general/allowRemoteLogin")[1]
                  if value == 'always':
                      return True
                  elif (value == 'requireSetPassword' and
                        self.username == 'admin' and
                        self.password != 'changeme'):
                      return True
                  else:
                      return False
              except KeyError:
                  return False
      
          def set_allow_remote_login(self, value='always'):
              """
              Set allowRemoteLogin to always.
              7.1+ behavior is not changed due to SPL-160369
              """
              restart_req = False
              if (isinstance(self.splunk, SimpleSplunk) and
                      self.username == 'admin' and
                      self.password == 'changeme'):
                  raise ValueError("Either SSH access should be provided to Splunk"
                                   "or admin password should be changed")
      
              if (value == 'requireSetPassword' and
                      self.password == 'changeme'):
                  raise ValueError("Admin password should be changed to something"
                                   "other than changeme")
      
              elif self.is_local():
                  self._splunk.create_logged_in_connector(
                      username=self.username,
                      password=self.password)
                  self._splunk.confs().create('server')
                  allow_remote_login = self._splunk.confs()[
                      'server']['general']['allowRemoteLogin']
      
                  if allow_remote_login != value:
                      self.logger.info("Setting remoteLogin for a local instance")
                      self._splunk.confs()['server']['general'][
                          'allowRemoteLogin'] = value
                      restart_req = True
      
              elif self.password == 'changeme':
                  self.logger.info("Setting remoteLogin for a remote instance")
                  self.connection.execute(
                      "curl -u admin:{password} -k "
                      "https://localhost:{mgmt_port}"
                      "/servicesNS/nobody/system/properties/server/general/ "
                      "-d 'allowRemoteLogin={new_value}'".format(
                          mgmt_port=self.splunkd_port(),
                          password=self.password,
                          new_value=value))
                  restart_req = True
      
              else:
                  if self.server_info.get('instance_type') != 'cloud':
                      with self.rest.namespace('nobody', 'system'):
                          self.rest.edit_property(
                              'server', 'general', **{'allowRemoteLogin': value})
                  else:
                      # It is a Splunk Cloud instance hence remoteLogin is enabled
                      self.logger.info("Cloud Splunk instance detected so "
                                       "remoteLogin is already enabled")
                  return
      
              if restart_req:
                  self._splunk.restart()
      
          def disable_instrumentation_modal(self, restart_req=True, use_rest=True):
              """
              Disable instrumentation modal
      
              :type restart_req: bool
              :param restart_req: request to restart splunk
                                  after config change or not
              :param use_rest: Restart Splunk via REST or not, default is True to
              keep consistent in theatre.
              :rtype: bool
              :return: True if instrumentation config change is made
              """
              with self.rest.namespace('nobody', 'splunk_instrumentation'):
                  instrumentation_settings = json.loads(
                      self.rest.get_telemetry('general', output_mode='json')[1])
      
                  if 'entry' in instrumentation_settings:
                      opt_in_version_ack = (
                          instrumentation_settings['entry'][0]['content']
                          .get('optInVersionAcknowledged'))
                      opt_in_version = (
                          instrumentation_settings['entry'][0]['content']
                          .get('optInVersion'))
                      self.logger.info(
                          "optInVersionAcknowledged is {} and optInVersion is {}"
                          "".format(opt_in_version_ack, opt_in_version))
      
                      if opt_in_version_ack != opt_in_version:
                          self.logger.info(
                              "Setting Instrumentation version to {v} to avoid "
                              "modal appearing on login".format(v=opt_in_version))
                          self.rest.edit_telemetry(
                              'general',
                              **{"showOptInModal": 0,
                                 "optInVersionAcknowledged": opt_in_version})
      
                          if restart_req:
                              self.restart(use_rest=use_rest)
      
                          # instrumentation config changed
                          return True
      
              # nothing changed
              return False
      
          def disable_python_3_impact_modal(self):
              """
              Disable Python 3 notification modal
              :rtype: bool
              :return: True if user-prefs config change is made
              """
              with self.rest.namespace('nobody', 'search'):
                  self.rest.edit_user_pref(
                      'general_default', **{"notification_python_3_impact": False})
      
                  # user-prefs config changed
                  return True
      
          @property
          @deprecated
          def server_name(self):
              """
              Gets the spunk server name
              """
              return self.nobody_rest.get_property(
                  'server', 'general/serverName')[1]
      
          @server_name.setter
          @deprecated
          def server_name(self, server_name):
              """
              Configure server name.
              Restart is required later to take effect.
      
              :param server_name: the specified server name
              """
              self.nobody_rest.edit_property(
                  'server', 'general', serverName=server_name)
      
          @property
          @deprecated
          def puppet_type(self):
              """
              Get the clustering mode and returns the cluster node if clustering is
              on and 'standalone' if clustering is disabled.
              The mode can be master, searchhead, slave and standalone.
      
              :rtype: string
              :return: the clustering mode.
              """
              clustering_mode = self.nobody_rest.get_property(
                  'server',
                  sub_endpoint='clustering/mode',
                  output_mode='json')[1]
              if clustering_mode == 'disabled':
                  return 'standalone'
              return clustering_mode
      
          @contextlib.contextmanager
          def settings(self, settings, restart=True, timeout=120, use_rest=True):
              """
              Change conf file settings in context. See following usage example:
              >>> with self.settings(settings, use_rest=False):
              >>>     ......
      
              :type settings: dict
              :param settings: dictionary of .conf settings
      
              :type restart: bool
              :param restart: restart splunk to make the changes take effect
      
              :type timeout: int
              :param timeout: timeout time of restart splunk
      
              :type use_rest: bool
              :param use_rest: Restart Splunk via REST or not, default is True to
                               keep consistent in theatre.
              """
              original_settings = self.configure_settings(settings)
              self.logger.debug('original_settings: {}'.format(original_settings))
              if restart:
                  self.restart(timeout=timeout, use_rest=use_rest)
              try:
                  yield
              finally:
                  self.revert_settings(original_settings)
                  if restart:
                      self.restart(timeout=timeout, use_rest=use_rest)
      
          def _get_app_path(self, user_namespace, app_namespace):
              """
              :type user_namespace: str
              :param user_namespace: user namespace
              :type app_namespace: str
              :param app_namespace: app namespace
              :rtype: str
              :return: absolute splunk app path
              """
              if user_namespace == 'nobody':
                  if app_namespace == 'system':
                      app_path = os.path.join(
                          self._splunk.splunk_home, 'etc', app_namespace)
                  else:
                      app_path = os.path.join(
                          self._splunk.splunk_home, 'etc', 'apps', app_namespace)
              else:
                  app_path = os.path.join(
                      self._splunk.splunk_home, 'etc', 'users',
                      user_namespace, app_namespace)
              return app_path
      
          def configure_settings(self, settings):
              """
              configure the .conf file settings, calling restart()
               to make settings effective
      
              :type settings: dict
              :param settings: dictionary of .conf settings
      
              :rtype: dict
              :return: original conf file settings
              """
              original_settings = copy.deepcopy(settings)
              rest_only = self.splunk_home is None
      
              for user_namespace, apps in settings.items():
                  for app_namespace, app_settings in apps.items():
                      self.rest.change_namespace(user_namespace, app_namespace)
                      ori_app_settings = original_settings[user_namespace][
                          app_namespace]
                      for conf_file in app_settings.keys():
                          if not rest_only:
                              local_conf_path = os.path.join(
                                  self._get_app_path(user_namespace, app_namespace),
                                  'local', '{}.conf'.format(conf_file))
      
                          status = self.rest.get_property(
                              conf_file, output_mode='json')[0]['status']
      
                          if status == '404':
                              self.logger.debug(
                                  '{}.conf is not found.'.format(conf_file))
                              self.rest.create_property(
                                  output_mode='json', **{'__conf': conf_file})
                              ori_app_settings[conf_file] = None
                          elif not rest_only:
                              if self.fileutils.isfile(local_conf_path):
                                  self.logger.debug(
                                      '{} exists. Save the original '
                                      'conf settings.'.format(local_conf_path))
                                  ori_contents = self.fileutils.get_file_contents(
                                      local_conf_path)
                                  ori_app_settings[conf_file] = ori_contents
                              else:
                                  self.logger.debug(
                                      '{} does not exist.'.format(local_conf_path))
                                  ori_app_settings[conf_file] = None
      
                          if not rest_only and app_settings[conf_file] is None:
                              if self.fileutils.isfile(local_conf_path):
                                  self.fileutils.delete_file(local_conf_path)
                          else:
                              for stanza in app_settings[conf_file].keys():
                                  url_quoted_stanza = urllib.quote(stanza, safe='')
                                  if self.rest.get_property(
                                          conf_file, sub_endpoint=url_quoted_stanza,
                                          output_mode='json')[0]['status'] == '404':
                                      self.rest.edit_property(
                                          conf_file, **{'__stanza': stanza})
                                  for attr, value in app_settings[conf_file][
                                          stanza].items():
                                      self.rest.edit_property(
                                          conf_file, sub_endpoint=url_quoted_stanza,
                                          output_mode='json', **{attr: value})
              if rest_only:
                  self.logger.warn('The return value of configure_settings() may be '
                                   'incorrect for REST only connection.')
              return original_settings
      
          def revert_settings(self, settings):
              """
              revert settings done by method configure_settings, calling restart()
              to make settings effective
      
              :type settings: dict
              :param settings: dictionary of .conf settings
              """
              for user_namespace, apps in settings.items():
                  for app_namespace, app_settings in apps.items():
                      self.rest.change_namespace(user_namespace, app_namespace)
                      for conf_file in app_settings.keys():
                          local_conf_path = os.path.join(
                              self._get_app_path(user_namespace, app_namespace),
                              'local', '{}.conf'.format(conf_file))
      
                          if app_settings[conf_file] is None:
                              self.logger.debug(
                                  'There was no {} originally. '
                                  'Delete it.'.format(local_conf_path))
                              if self.fileutils.isfile(local_conf_path):
                                  self.fileutils.delete_file(local_conf_path)
                          else:
                              self.logger.debug(
                                  'There was {} originally. '
                                  'Revert the settings to original ones.'.format(
                                      local_conf_path))
                              self.fileutils.write_file_contents(
                                  local_conf_path, app_settings[conf_file],
                                  mode='wb')
      
          def create_settings_dict(
                  self, user, app, conf_file, stanza, key_val_pairs=None):
              \'''
              returns a dict which can be passed to the configure_settings method of
              Puppet
              \'''
              key_val_pairs = key_val_pairs if key_val_pairs else {}
              return {user: {app: {conf_file: {stanza: key_val_pairs}}}}
      
          def method_missing(self, attr, *args, **kwargs):
              if hasattr(self.splunk, "{a}".format(a=attr)):
                  return getattr(self.splunk, attr)
              else:
                  msg = "Splunk doesn't respond to: '{a}'".format(a=attr)
                  raise AttributeError(msg)
      
          def __str__(self):
              """
              Strings for users
              """
              if self.is_running():
                  return 'splunkweb={w}, splunkd={d}'.format(
                      w=self.web_base(), d=self.uri_base())
              else:
                  return 'host={}'.format(self.host_ip)
      
          def __repr__(self):
              """
              Strings for developers
              """
              if self.is_running():
                  return '{p}({s}(splunkweb={w}, splunkd={d}))'.format(
                      p=self.__class__.__name__, s=self._splunk.__class__.__name__,
                      w=self.web_base(), d=self.uri_base())
              else:
                  return '{p}({s}(host={h}))'.format(
                      p=self.__class__.__name__, s=self._splunk.__class__.__name__,
                      h=self.host_ip)
      
          def __eq__(self, other):
              """
              Check if two puppets are equal
      
              :type other: Puppet
              :param other: another puppet
      
              :rtype: bool
              :return: True if equal
              """
              if isinstance(other, SplunkPuppet):
                  return self.splunk == other.splunk
              else:
                  return NotImplemented
      
          def __hash__(self):
              """
              Gets the hash value
      
              :rtype: int
              :return: hash value
              """
              return hash(self._splunk)
      
          @classmethod
          def generate_accessors(cls, name=None, plural_name=None):
              """
              Generate accessor methods
      
              :type name: str
              :param name: the specified singular name
      
              :type plural_name: str
              :param plural_name: the specified plural name
              """
              # Generate as-method in Puppet
      
              def gen_as_method(self):
                  return cls(self.splunk)
      
              if name is None:
                  # e.g. DMCServer -> DMC_Server
                  name = re.sub(
                      r'([A-Z]+)([A-Z][a-z])', r'\\1_\\2', cls.__name__)
                  # e.g. SearchHead -> Search_Head
                  name = re.sub(
                      r'([a-z\\d])([A-Z])', r'\\1_\\2', name)
                  name = name.lower()
      
              gen_as_method.__doc__ = \'''
                  as {c}
                  \'''.format(c=cls.__name__)
              gen_as_method.__name__ = 'as_{n}'.format(n=name)
              setattr(SplunkPuppet, gen_as_method.__name__, property(gen_as_method))
      
              # Generate property in Stage and Site
              from theatre.stages import Stage
              from theatre.stages import Site
      
              generate_puppet_property(Stage, 'puppets', source_class=SplunkPuppet)
              generate_puppet_property(Site, 'puppets', source_class=SplunkPuppet)
      
              property_name = ('{n}s'.format(n=name)
                               if plural_name is None else plural_name)
              generate_puppet_property(Stage, property_name, source_class=cls)
      
      
      def generate_puppet_property(target_class, property_name, source_class):
          """
          Generate puppet property in the target class
      
          :type target_class: class
          :param target_class: the specified target class
      
          :type property_name: str
          :param property_name: the specified property name generated
      
          :type source_class: class
          :param source_class: the specified source class
          """
          property_doc_name = property_name.replace('_', ' ')
          field_name = '_{n}'.format(n=property_name)
      
          def get_puppets(self):
              return Puppeteer(getattr(self, field_name, []))
      
          get_puppets.__doc__ = \'''
              Gets puppeteer of {n}
              \'''.format(n=property_doc_name)
          get_puppets.__name__ = property_name
      
          def set_puppets(self, splunks):
              splunks = splunks or []
              setattr(
                  self, field_name,
                  [splunk if isinstance(splunk, source_class) else
                   source_class(splunk) for splunk in splunks])
      
          set_puppets.__doc__ = \'''
              Sets {n}
      
              :type splunks: list
              :param splunks: the specified splunks for {n}
              \'''.format(n=property_doc_name)
          set_puppets.__name__ = 'set_{n}'.format(n=property_name)
      
          setattr(target_class, property_name,
                  property(get_puppets, set_puppets))
      
      
      # Alias for backwards compatibility
      Puppet = SplunkPuppet
      
    '''
    linesHighlighted: []
  }
  {
    name: ""
    mode: "Python"
    content: '''
      #!/usr/bin/python
      # vim: set fileencoding=utf-8 :
      
      import errno
      import json
      import logging
      from socket import gethostbyname
      
      import re
      import os
      import copy
      import httplib
      import socket
      import rip
      import contextlib
      import urllib
      from sharedtestutils.MethodMissing import MethodMissing
      from sharedtestutils.decorators import deprecated
      from sharedtestutils.decorators import deprecated_by
      
      from ..puppeteers import Puppeteer
      from ..utils.monitorlog import HttpInput
      
      
      TRUE_VALUES = (True, 't', 'true', '1', 1)
      
      
      class SimpleSplunk(object):
          """
          The Simple Splunk for REST-only splunk instance
          """
      
          def __init__(
                  self, web_host='localhost', splunkd_host='localhost',
                  web_port='8000', splunkd_port='8089',
                  username='admin', password='changeme', name=None):
              """
              SimpleSplunk init
      
              :param web_host: the specified splunkweb host
              :param splunkd_host: the specified splunkd host
              :param web_port: the specified splunkweb port
              :param splunkd_port: the specified splunkd port
              :param username: the specified splunk username
              :param password: the specified splunk password
              :param name: the specified instance name
              """
              self._web_host = web_host
              self._splunkd_host = splunkd_host
              self._web_port = web_port
              self._splunkd_port = splunkd_port
              self._username = username
              self._password = password
              self._name = name or splunkd_host
      
          def web_host(self):
              """
              Gets splunkweb host
      
              :rtype: str
              :return: splunkweb host
              """
              return self._web_host
      
          def splunkd_host(self):
              """
              Gets splunkd host
      
              :rtype: str
              :return: splunkd host
              """
              return self._splunkd_host
      
          def web_port(self):
              """
              Gets splunkweb port
      
              :rtype: int
              :return: splunkweb port
              """
              return self._web_port
      
          def splunkd_port(self):
              """
              Gets splunkd port
      
              :rtype: int
              :return: splunkd port
              """
              return self._splunkd_port
      
          def uri_base(self):
              """
              Gets splunkd uri base
      
              :rtype: str
              :return: splunkd uri base
              """
              return 'https://{h}:{p}'.format(
                  h=self.splunkd_host(), p=self.splunkd_port())
      
          @property
          def username(self):
              """
              Gets splunk username
      
              :rtype: str
              :return: splunk username
              """
              return self._username
      
          @property
          def password(self):
              """
              Gets splunk password
      
              :rtype: str
              :return: splunk password
              """
              return self._password
      
          @property
          def name(self):
              """
              Gets splunk name
      
              :rtype: str
              :return: splunk name
              """
              return self._name
      
          @property
          def splunk_home(self):
              """
              Gets splunk home
      
              :rtype: str
              :return: splunk home
              """
              return None
      
      
      class PuppetStatus(object):
          """
          Puppet status enum
          """
          RUNNING = 1
          STOPPED = 2
      
      
      class BasePuppet(MethodMissing):
          """
          Base class for puppet, which represents one instance in splunk deployment
          """
      
          def __init__(self):
              """
              BasePuppet Init
              """
              super(BasePuppet, self).__init__()
              self.logger = logging.getLogger(self.__class__.__name__)
      
          @property
          def status(self):
              """
              Returns the puppet status
              """
              raise NotImplementedError
      
      
      class SplunkPuppet(BasePuppet):
          """
          Puppet manages one splunk instance
          """
      
          def __init__(self, splunk):
              """
              SplunkPuppet init
      
              :type splunk: Splunk
              :param splunk: the specified splunk instance
              """
              super(SplunkPuppet, self).__init__()
              self._splunk = splunk
              self._init_rest()
              self.logger = logging.getLogger(self.__class__.__name__)
      
          @property
          @deprecated
          def splunk(self):
              """
              Gets the wrapped splunk instance
              """
              return self._splunk
      
          @property
          def fileutils(self):
              """
              Gets the splunk fileutils
              """
              return self._splunk.fileutils
      
          @property
          def splunk_home(self):
              """
              Gets the splunk home
      
              :rtype: str
              :return: splunk home
              """
              return self._splunk.splunk_home
      
          @property
          def username(self):
              """
              Gets splunk username
      
              :rtype: str
              :return: splunk username
              """
              return self._splunk.username
      
          @property
          def password(self):
              """
              Gets splunk password
      
              :rtype: str
              :return: splunk password
              """
              return self._splunk.password
      
          def splunkd_host(self):
              """
              Gets splunkd host
      
              :rtype: str
              :return: splunkd host
              """
              return self._splunk.splunkd_host()
      
          def splunkd_port(self):
              """
              Gets splunkd port
      
              :rtype: int
              :return: splunkd port
              """
              return self._splunk.splunkd_port()
      
          def splunkd_scheme(self):
              """
              Gets splunkd scheme
      
              :rtype: str
              :return: The splunkd scheme
              """
              return 'https' if self._is_splunkd_ssl_enabled() else 'http'
      
          def web_host(self):
              """
              Gets web host
      
              :rtype: str
              :return: web host
              """
              return self._splunk.web_host()
      
          def web_port(self):
              """
              Gets web port
      
              :rtype: int
              :return: web port
              """
              return self._splunk.web_port()
      
          def web_scheme(self):
              """
              Gets splunkweb scheme
      
              :rtype: str
              :return: The splunkweb scheme
              """
              return 'https' if self._is_web_ssl_enabled() else 'http'
      
          def _init_rest(self):
              """
              Init rest
              """
              conn = rip.RESTConnectorReplacement(
                  username=self.username, password=self.password,
                  uri_base=self.uri_base())
      
              self.rest = rip.RESTInPeace(conn)
      
          @property
          @deprecated
          def nobody_rest(self):
              """
              Gets nobody rest with system namespace
              """
              self.rest.change_namespace('nobody', 'system')
              return self.rest
      
          def token_rest(self, token):
              """
              Get rest with token
              """
              conn = rip.RESTConnectorReplacement(
                  username=self.username,
                  password=self.password,
                  uri_base=self.uri_base(),
                  token=token)
              return rip.RESTInPeace(conn)
      
          def get_http_input(self, token, port='8088', ack=False, ssl=False):
              """
              Get http event collector object
      
              :param token: http event collector token
              :type token: str
      
              :param port: http event collector port number
              :type port: str
      
              :param ack: should use ack
              :type ack: bool
      
              :param ssl: should use ssl
              :type ssl: bool
      
              :return: http event collector object
              :rtype: HttpInput
              """
              return HttpInput(
                  host=self.web_host(),
                  port=port,
                  token=token,
                  ack=ack,
                  ssl=ssl)
      
          def uri_base(self, scheme=True, use_server_name=False):
              """
              Gets splunk uri base url
      
              :param scheme: if true, result contains the uri scheme
                             if false, only the raw uri will be returned
              :type scheme: bool
      
              :param use_server_name: use host name but not ip
                                      if set this value as True
              :type use_server_name: bool
      
              :return: the uri base
              :rtype: str
              """
              if use_server_name:
                  _uri_base = '{scheme}://{host}:{web_port}'.format(
                      scheme=self.splunkd_scheme(),
                      host=self.server_name,
                      web_port=self.splunkd_port())
              else:
                  _uri_base = self._splunk.uri_base()
      
              if not scheme:
                  _uri_base = re.sub("http.?://", "", _uri_base)
      
              return _uri_base
      
          def web_base(self):
              """
              Gets splunk web base url
              """
              root_endpoint = self._get_root_endpoint()
              web_base = "{scheme}://{host}:{web_port}{end_point}".format(
                  scheme=self.web_scheme(), host=self.web_host(),
                  web_port=self.web_port(),
                  end_point=root_endpoint if root_endpoint != '/' else '')
              return web_base
      
          def _get_root_endpoint(self):
              """
              Gets root endpoint in settings.
              """
              return self.rest.get_property('web', 'settings/root_endpoint')[1]
      
          def _is_web_ssl_enabled(self):
              """
              Return True if splunk web ssl is enabled
              """
              result = self.rest.get_property(
                  'web', 'settings/enableSplunkWebSSL')[1]
              return result.lower() in TRUE_VALUES
      
          def _is_splunkd_ssl_enabled(self):
              """
              Return True if splunkd ssl is enabled
              """
              result = self.rest.get_property(
                  'server', 'sslConfig/enableSplunkdSSL')[1]
              return result.lower() in TRUE_VALUES
      
          def restart(self, timeout=360, use_rest=True):
              """
              Restart splunk instance
              :param use_rest: Restart Splunk via REST or not, default is True.
              :param timeout: REST restart time
              """
              if use_rest:
                  self.rest.restart(timeout=timeout)
                  if hasattr(self.splunk, '_splunk_has_started'):
                      self.splunk._splunk_has_started()
              else:
                  # Restart Splunk by native way rather than REST.
                  # If no 'self.splunk.restart()' then fallback restart via REST
                  try:
                      self.splunk.restart()
                  except AttributeError:
                      self.rest.restart(timeout=timeout)
              self._init_rest()
      
          def start(self, **kwargs):
              """
              Start splunk instance
              """
              self._splunk.start(**kwargs)
              self._init_rest()
      
          def stop(self):
              """
              Stop splunk instance
              """
              self._splunk.stop()
      
          @property
          def name(self):
              """
              Gets splunk name
              """
              return self._splunk.name
      
          @property
          def connection(self):
              """
              Gets the ssh connection that is used
      
              :rtype: SSHConnection
              :return: ssh connection
              """
              return self._splunk.connection
      
          def is_local(self):
              """
              Check if the splunk is local instance
              """
              return self.splunkd_host() in ['localhost', '127.0.0.1', '::1']
      
          def is_running(self):
              """
              Check if the splunk is running
              """
              try:
                  with self.rest.namespace('nobody', 'system'):
                      resp = self.rest.run_info(output_mode='json')[0]['status']
                      if int(resp) in self.rest.SUCCESS_CODES:
                          return True
                      else:
                          self.logger.warn(
                              'Splunkd is accessible but we are unable to '
                              'successfully get the server info.')
                          return False
              except (socket.error, httplib.HTTPException) as err:
                  self.logger.warn('[socket, http exception]Failed to check if'
                                   ' splunk is running: {}'.format(err))
                  return False
              except Exception as err:
      
                  # handle expected errors to be False and raise everything else
                  if getattr(err, 'errno', None) in [errno.ECONNREFUSED,
                                                     errno.EHOSTDOWN,
                                                     errno.ECONNRESET]:
                      self.logger.warn(
                          'Failed to check if splunk is running: {e}'.format(e=err))
                      return False
                  raise
      
          @property
          def status(self):
              """
              Returns the status of the splunk
              :rtype: PuppetStatus
              """
              return (PuppetStatus.RUNNING if self.is_running()
                      else PuppetStatus.STOPPED)
      
          @property
          def version(self):
              """
              Gets splunk version
      
              :rtype: str
              :return: splunk version
              """
              server_info = self.server_info
              return 'Splunk {t} {v} (build {b})'.format(
                  t=server_info['product_type'],
                  v=server_info['version'],
                  b=server_info['build'])
      
          @property
          @deprecated_by('server_info')
          def info_content(self):
              """
              Gets the server info
      
              :rtype: dict
              :return: server info dict
              """
              return self.server_info
      
          @property
          def server_info(self):
              """
              Gets the server info
      
              :rtype: dict
              :return: server info dict
                       return empty dict if is not running
              """
              if self.is_running():
                  with self.rest.namespace('nobody', 'system'):
                      return json.loads(
                          self.rest.run_info(
                              output_mode='json')[1])['entry'][0]['content']
              else:
                  return {}
      
          def has_server_role(self, server_role):
              """
              Check if the puppet has the specified server role.
      
              :type server_role: str
              :param server_role: the specified server role to check
      
              :rtype: bool
              :return: True if the puppet has the specified server role
              """
              server_info = self.server_info
              return ('server_roles' in server_info and
                      server_role in server_info['server_roles'])
      
          @property
          def host_os(self):
              \'''
              Gets the host OS, e.g. 'Linux', 'Windows', or 'Darwin'.
      
              :return: Operating System of the host machine
              :rtype: string
              \'''
              host_os = self._splunk.get_host_os()
              # in windows orca env, os type returned is cygwin_nt-10.0-14393, which
              # is returned by helmut, work it around with the fix.
              if 'cygwin_nt' in host_os.lower():
                  return 'Windows'
              return host_os
      
          @property
          def host_ip(self):
              \'''
              Gets the ip address of the machine hosting this puppet
              \'''
              return gethostbyname(self._splunk.splunkd_host())
      
          @property
          def host_arch(self):
              \'''
              Get the host architecture
      
              :return: architecture of the host machine (64 bit/ 32 bit)
              :rtype: string
              \'''
              return self._splunk.get_host_platform()
      
          def is_remote_login_enabled(self):
              """
              Check if remote login is enabled.
              7.1+ behavior is not changed due to SPL-160369
              """
              try:
                  value = self.nobody_rest.get_property(
                      "server", "general/allowRemoteLogin")[1]
                  if value == 'always':
                      return True
                  elif (value == 'requireSetPassword' and
                        self.username == 'admin' and
                        self.password != 'changeme'):
                      return True
                  else:
                      return False
              except KeyError:
                  return False
      
          def set_allow_remote_login(self, value='always'):
              """
              Set allowRemoteLogin to always.
              7.1+ behavior is not changed due to SPL-160369
              """
              restart_req = False
              if (isinstance(self.splunk, SimpleSplunk) and
                      self.username == 'admin' and
                      self.password == 'changeme'):
                  raise ValueError("Either SSH access should be provided to Splunk"
                                   "or admin password should be changed")
      
              if (value == 'requireSetPassword' and
                      self.password == 'changeme'):
                  raise ValueError("Admin password should be changed to something"
                                   "other than changeme")
      
              elif self.is_local():
                  self._splunk.create_logged_in_connector(
                      username=self.username,
                      password=self.password)
                  self._splunk.confs().create('server')
                  allow_remote_login = self._splunk.confs()[
                      'server']['general']['allowRemoteLogin']
      
                  if allow_remote_login != value:
                      self.logger.info("Setting remoteLogin for a local instance")
                      self._splunk.confs()['server']['general'][
                          'allowRemoteLogin'] = value
                      restart_req = True
      
              elif self.password == 'changeme':
                  self.logger.info("Setting remoteLogin for a remote instance")
                  self.connection.execute(
                      "curl -u admin:{password} -k "
                      "https://localhost:{mgmt_port}"
                      "/servicesNS/nobody/system/properties/server/general/ "
                      "-d 'allowRemoteLogin={new_value}'".format(
                          mgmt_port=self.splunkd_port(),
                          password=self.password,
                          new_value=value))
                  restart_req = True
      
              else:
                  if self.server_info.get('instance_type') != 'cloud':
                      with self.rest.namespace('nobody', 'system'):
                          self.rest.edit_property(
                              'server', 'general', **{'allowRemoteLogin': value})
                  else:
                      # It is a Splunk Cloud instance hence remoteLogin is enabled
                      self.logger.info("Cloud Splunk instance detected so "
                                       "remoteLogin is already enabled")
                  return
      
              if restart_req:
                  self._splunk.restart()
      
          def disable_instrumentation_modal(self, restart_req=True, use_rest=True):
              """
              Disable instrumentation modal
      
              :type restart_req: bool
              :param restart_req: request to restart splunk
                                  after config change or not
              :param use_rest: Restart Splunk via REST or not, default is True to
              keep consistent in theatre.
              :rtype: bool
              :return: True if instrumentation config change is made
              """
              with self.rest.namespace('nobody', 'splunk_instrumentation'):
                  instrumentation_settings = json.loads(
                      self.rest.get_telemetry('general', output_mode='json')[1])
      
                  if 'entry' in instrumentation_settings:
                      opt_in_version_ack = (
                          instrumentation_settings['entry'][0]['content']
                          .get('optInVersionAcknowledged'))
                      opt_in_version = (
                          instrumentation_settings['entry'][0]['content']
                          .get('optInVersion'))
                      self.logger.info(
                          "optInVersionAcknowledged is {} and optInVersion is {}"
                          "".format(opt_in_version_ack, opt_in_version))
      
                      if opt_in_version_ack != opt_in_version:
                          self.logger.info(
                              "Setting Instrumentation version to {v} to avoid "
                              "modal appearing on login".format(v=opt_in_version))
                          self.rest.edit_telemetry(
                              'general',
                              **{"showOptInModal": 0,
                                 "optInVersionAcknowledged": opt_in_version})
      
                          if restart_req:
                              self.restart(use_rest=use_rest)
      
                          # instrumentation config changed
                          return True
      
              # nothing changed
              return False
      
          def disable_python_3_impact_modal(self):
              """
              Disable Python 3 notification modal
              :rtype: bool
              :return: True if user-prefs config change is made
              """
              with self.rest.namespace('nobody', 'search'):
                  self.rest.edit_user_pref(
                      'general_default', **{"notification_python_3_impact": False})
      
                  # user-prefs config changed
                  return True
      
          @property
          @deprecated
          def server_name(self):
              """
              Gets the spunk server name
              """
              return self.nobody_rest.get_property(
                  'server', 'general/serverName')[1]
      
          @server_name.setter
          @deprecated
          def server_name(self, server_name):
              """
              Configure server name.
              Restart is required later to take effect.
      
              :param server_name: the specified server name
              """
              self.nobody_rest.edit_property(
                  'server', 'general', serverName=server_name)
      
          @property
          @deprecated
          def puppet_type(self):
              """
              Get the clustering mode and returns the cluster node if clustering is
              on and 'standalone' if clustering is disabled.
              The mode can be master, searchhead, slave and standalone.
      
              :rtype: string
              :return: the clustering mode.
              """
              clustering_mode = self.nobody_rest.get_property(
                  'server',
                  sub_endpoint='clustering/mode',
                  output_mode='json')[1]
              if clustering_mode == 'disabled':
                  return 'standalone'
              return clustering_mode
      
          @contextlib.contextmanager
          def settings(self, settings, restart=True, timeout=120, use_rest=True):
              """
              Change conf file settings in context. See following usage example:
              >>> with self.settings(settings, use_rest=False):
              >>>     ......
      
              :type settings: dict
              :param settings: dictionary of .conf settings
      
              :type restart: bool
              :param restart: restart splunk to make the changes take effect
      
              :type timeout: int
              :param timeout: timeout time of restart splunk
      
              :type use_rest: bool
              :param use_rest: Restart Splunk via REST or not, default is True to
                               keep consistent in theatre.
              """
              original_settings = self.configure_settings(settings)
              self.logger.debug('original_settings: {}'.format(original_settings))
              if restart:
                  self.restart(timeout=timeout, use_rest=use_rest)
              try:
                  yield
              finally:
                  self.revert_settings(original_settings)
                  if restart:
                      self.restart(timeout=timeout, use_rest=use_rest)
      
          def _get_app_path(self, user_namespace, app_namespace):
              """
              :type user_namespace: str
              :param user_namespace: user namespace
              :type app_namespace: str
              :param app_namespace: app namespace
              :rtype: str
              :return: absolute splunk app path
              """
              if user_namespace == 'nobody':
                  if app_namespace == 'system':
                      app_path = os.path.join(
                          self._splunk.splunk_home, 'etc', app_namespace)
                  else:
                      app_path = os.path.join(
                          self._splunk.splunk_home, 'etc', 'apps', app_namespace)
              else:
                  app_path = os.path.join(
                      self._splunk.splunk_home, 'etc', 'users',
                      user_namespace, app_namespace)
              return app_path
      
          def configure_settings(self, settings):
              """
              configure the .conf file settings, calling restart()
               to make settings effective
      
              :type settings: dict
              :param settings: dictionary of .conf settings
      
              :rtype: dict
              :return: original conf file settings
              """
              original_settings = copy.deepcopy(settings)
              rest_only = self.splunk_home is None
      
              for user_namespace, apps in settings.items():
                  for app_namespace, app_settings in apps.items():
                      self.rest.change_namespace(user_namespace, app_namespace)
                      ori_app_settings = original_settings[user_namespace][
                          app_namespace]
                      for conf_file in app_settings.keys():
                          if not rest_only:
                              local_conf_path = os.path.join(
                                  self._get_app_path(user_namespace, app_namespace),
                                  'local', '{}.conf'.format(conf_file))
      
                          status = self.rest.get_property(
                              conf_file, output_mode='json')[0]['status']
      
                          if status == '404':
                              self.logger.debug(
                                  '{}.conf is not found.'.format(conf_file))
                              self.rest.create_property(
                                  output_mode='json', **{'__conf': conf_file})
                              ori_app_settings[conf_file] = None
                          elif not rest_only:
                              if self.fileutils.isfile(local_conf_path):
                                  self.logger.debug(
                                      '{} exists. Save the original '
                                      'conf settings.'.format(local_conf_path))
                                  ori_contents = self.fileutils.get_file_contents(
                                      local_conf_path)
                                  ori_app_settings[conf_file] = ori_contents
                              else:
                                  self.logger.debug(
                                      '{} does not exist.'.format(local_conf_path))
                                  ori_app_settings[conf_file] = None
      
                          if not rest_only and app_settings[conf_file] is None:
                              if self.fileutils.isfile(local_conf_path):
                                  self.fileutils.delete_file(local_conf_path)
                          else:
                              for stanza in app_settings[conf_file].keys():
                                  url_quoted_stanza = urllib.quote(stanza, safe='')
                                  if self.rest.get_property(
                                          conf_file, sub_endpoint=url_quoted_stanza,
                                          output_mode='json')[0]['status'] == '404':
                                      self.rest.edit_property(
                                          conf_file, **{'__stanza': stanza})
                                  for attr, value in app_settings[conf_file][
                                          stanza].items():
                                      self.rest.edit_property(
                                          conf_file, sub_endpoint=url_quoted_stanza,
                                          output_mode='json', **{attr: value})
              if rest_only:
                  self.logger.warn('The return value of configure_settings() may be '
                                   'incorrect for REST only connection.')
              return original_settings
      
          def revert_settings(self, settings):
              """
              revert settings done by method configure_settings, calling restart()
              to make settings effective
      
              :type settings: dict
              :param settings: dictionary of .conf settings
              """
              for user_namespace, apps in settings.items():
                  for app_namespace, app_settings in apps.items():
                      self.rest.change_namespace(user_namespace, app_namespace)
                      for conf_file in app_settings.keys():
                          local_conf_path = os.path.join(
                              self._get_app_path(user_namespace, app_namespace),
                              'local', '{}.conf'.format(conf_file))
      
                          if app_settings[conf_file] is None:
                              self.logger.debug(
                                  'There was no {} originally. '
                                  'Delete it.'.format(local_conf_path))
                              if self.fileutils.isfile(local_conf_path):
                                  self.fileutils.delete_file(local_conf_path)
                          else:
                              self.logger.debug(
                                  'There was {} originally. '
                                  'Revert the settings to original ones.'.format(
                                      local_conf_path))
                              self.fileutils.write_file_contents(
                                  local_conf_path, app_settings[conf_file],
                                  mode='wb')
      
          def create_settings_dict(
                  self, user, app, conf_file, stanza, key_val_pairs=None):
              \'''
              returns a dict which can be passed to the configure_settings method of
              Puppet
              \'''
              key_val_pairs = key_val_pairs if key_val_pairs else {}
              return {user: {app: {conf_file: {stanza: key_val_pairs}}}}
      
          def method_missing(self, attr, *args, **kwargs):
              if hasattr(self.splunk, "{a}".format(a=attr)):
                  return getattr(self.splunk, attr)
              else:
                  msg = "Splunk doesn't respond to: '{a}'".format(a=attr)
                  raise AttributeError(msg)
      
          def __str__(self):
              """
              Strings for users
              """
              if self.is_running():
                  return 'splunkweb={w}, splunkd={d}'.format(
                      w=self.web_base(), d=self.uri_base())
              else:
                  return 'host={}'.format(self.host_ip)
      
          def __repr__(self):
              """
              Strings for developers
              """
              if self.is_running():
                  return '{p}({s}(splunkweb={w}, splunkd={d}))'.format(
                      p=self.__class__.__name__, s=self._splunk.__class__.__name__,
                      w=self.web_base(), d=self.uri_base())
              else:
                  return '{p}({s}(host={h}))'.format(
                      p=self.__class__.__name__, s=self._splunk.__class__.__name__,
                      h=self.host_ip)
      
          def __eq__(self, other):
              """
              Check if two puppets are equal
      
              :type other: Puppet
              :param other: another puppet
      
              :rtype: bool
              :return: True if equal
              """
              if isinstance(other, SplunkPuppet):
                  return self.splunk == other.splunk
              else:
                  return NotImplemented
      
          def __hash__(self):
              """
              Gets the hash value
      
              :rtype: int
              :return: hash value
              """
              return hash(self._splunk)
      
          @classmethod
          def generate_accessors(cls, name=None, plural_name=None):
              """
              Generate accessor methods
      
              :type name: str
              :param name: the specified singular name
      
              :type plural_name: str
              :param plural_name: the specified plural name
              """
              # Generate as-method in Puppet
      
              def gen_as_method(self):
                  return cls(self.splunk)
      
              if name is None:
                  # e.g. DMCServer -> DMC_Server
                  name = re.sub(
                      r'([A-Z]+)([A-Z][a-z])', r'\\1_\\2', cls.__name__)
                  # e.g. SearchHead -> Search_Head
                  name = re.sub(
                      r'([a-z\\d])([A-Z])', r'\\1_\\2', name)
                  name = name.lower()
      
              gen_as_method.__doc__ = \'''
                  as {c}
                  \'''.format(c=cls.__name__)
              gen_as_method.__name__ = 'as_{n}'.format(n=name)
              setattr(SplunkPuppet, gen_as_method.__name__, property(gen_as_method))
      
              # Generate property in Stage and Site
              from theatre.stages import Stage
              from theatre.stages import Site
      
              generate_puppet_property(Stage, 'puppets', source_class=SplunkPuppet)
              generate_puppet_property(Site, 'puppets', source_class=SplunkPuppet)
      
              property_name = ('{n}s'.format(n=name)
                               if plural_name is None else plural_name)
              generate_puppet_property(Stage, property_name, source_class=cls)
      
      
      def generate_puppet_property(target_class, property_name, source_class):
          """
          Generate puppet property in the target class
      
          :type target_class: class
          :param target_class: the specified target class
      
          :type property_name: str
          :param property_name: the specified property name generated
      
          :type source_class: class
          :param source_class: the specified source class
          """
          property_doc_name = property_name.replace('_', ' ')
          field_name = '_{n}'.format(n=property_name)
      
          def get_puppets(self):
              return Puppeteer(getattr(self, field_name, []))
      
          get_puppets.__doc__ = \'''
              Gets puppeteer of {n}
              \'''.format(n=property_doc_name)
          get_puppets.__name__ = property_name
      
          def set_puppets(self, splunks):
              splunks = splunks or []
              setattr(
                  self, field_name,
                  [splunk if isinstance(splunk, source_class) else
                   source_class(splunk) for splunk in splunks])
      
          set_puppets.__doc__ = \'''
              Sets {n}
      
              :type splunks: list
              :param splunks: the specified splunks for {n}
              \'''.format(n=property_doc_name)
          set_puppets.__name__ = 'set_{n}'.format(n=property_name)
      
          setattr(target_class, property_name,
                  property(get_puppets, set_puppets))
      
      
      # Alias for backwards compatibility
      Puppet = SplunkPuppet
      
    '''
    linesHighlighted: []
  }
  {
    name: ""
    mode: "Python"
    content: '''
      #!/usr/bin/python
      # vim: set fileencoding=utf-8 :
      
      """
      Meta
      ====
          $Id$
          $DateTime$
          $Author$
          $Change$
      """
      from __future__ import unicode_literals
      
      import httplib
      import json
      import logging
      import ssl
      import urllib
      import urlparse
      from base64 import b64encode
      
      import os
      import tarfile
      import tempfile
      import zipfile
      import gzip
      import binascii
      import pytest
      import requests
      import rip
      from polling import poll_for_condition
      from sys import platform as _platform
      
      try:
          # The python standard library can be built without bz2 so we make bz2
          # usage optional.
          import bz2
      except ImportError:
          bz2 = None
      
      INDEX_WAIT = 120
      
      
      class PathNotFoundError(IOError):
          """
          Throw this error when the path you looking for is not found.
          """
          pass
      
      
      class FileNotFound(IOError):
          """
          Throw this error when file you looking for is not found.
          """
          pass
      
      
      class HECRequestException(Exception):
          """
          Throw this exception when HEC request failed.
          """
          pass
      
      
      def normalize_to_str(obj):
          """
          Utility to help normalize all objects and string
          to ascii representation.
      
          if unicode string -> ascii string
          if ascii string -> ascii string
          if object -> object.__str__()
      
          @type obj: object
          @param obj: strings or objects
      
          @rtype: ascii string
          @return: ascii representation of the object passed in.
          """
          if isinstance(obj, str):
              return obj
          elif isinstance(obj, unicode):
              return str(obj.encode('utf8'))
          else:
              return str(obj)
      
      
      def is_abs_path(path_value):
          """
          Workaround for INFRA-15819
      
          Check whether this is a abs path or not
          Below values are treated as abs path
              /opt/splunk
              C:\\opt\\splunk
      
          :param path_value: the path value
          :type path_value: str
      
          :rtype: bool
          """
          return (os.path.isabs(path_value) or (
                      len(path_value) > 2 and path_value[1] == ':'))
      
      
      class IndexLog(object):
          """
          Base class to index a log file.
      
          """
      
          def __init__(
                  self, logfile_name, logfile_dir, sourcetype, event_count, index,
                  source, username, password, mgmt_url, index_wait=INDEX_WAIT,
                  path_util=os.path, rest_settings=None):
              """
              @type logfile_name: string
              @param logfile_name: name of the log file
      
              @type logfile_dir: string
              @param logfile_dir: dir of the log file
      
              @type sourcetype: string
              @param sourcetype: name of sourcetype for the log file
      
              @type event_count: int
              @param event_count: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type source: string
              @param source: name of the source for the log file
      
              @type username: string
              @param username: the splunk username
      
              @type password: string
              @param password: the splunk password
      
              @type mgmt_url: string
              @param mgmt_url: the splunk managment url
      
              @type path_util: object
              @param path_util: the file path util
      
              @type index_wait: int
              @param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
              """
              # for tests/web/webdriver tests. there are params that will
              # set this up. ideally this should not be here.
      
              if ('config' in pytest.__dict__ and
                      'install_forwarder' in pytest.config.__dict__ and
                      pytest.config.install_forwarder):
      
                  if ('config' in pytest.__dict__
                          and 'forwarder_username' in pytest.config.__dict__):
                      pytest_username = pytest.config.forwarder_username
                  else:
                      pytest_username = None
      
                  if ('config' in pytest.__dict__
                          and 'forwarder_password' in pytest.config.__dict__):
                      pytest_password = pytest.config.forwarder_password
                  else:
                      pytest_password = None
      
              else:
      
                  if ('config' in pytest.__dict__
                          and 'admin_username' in pytest.config.__dict__):
                      pytest_username = pytest.config.admin_username
                  else:
                      pytest_username = None
      
                  if ('config' in pytest.__dict__
                          and 'admin_password' in pytest.config.__dict__):
                      pytest_password = pytest.config.admin_password
                  else:
                      pytest_password = None
      
              # set the management url regardless of forwarder or not.
              if ('config' in pytest.__dict__
                      and 'mgmt_url' in pytest.config.__dict__):
                  pytest_mgmt_url = pytest.config.mgmt_url
              else:
                  pytest_mgmt_url = None
      
              username = username or pytest_username or 'admin'
              password = password or pytest_password or 'changeme'
              mgmt_url = mgmt_url or pytest_mgmt_url
      
              self.logger = logging.getLogger(self.__class__.__name__)
              self.logfile_name = logfile_name
              self.logfile_dir = logfile_dir
              self.sourcetype = sourcetype
              self.event_count = event_count
              self.index = index
              self.source = source
              self.username = username
              self.password = password
              self.mgmt_url = mgmt_url
              self.index_wait = index_wait
      
              if rest_settings is None:
                  self.rest_settings = {}
              else:
                  self.rest_settings = rest_settings
      
              if ('config' in pytest.__dict__
                      and hasattr(pytest.config, 'saml_okta')
                      and pytest.config.saml_okta
                      and 'admin_username' in pytest.config.__dict__
                      and 'admin_password' in pytest.config.__dict__):
                  conn = rip.RESTConnectorReplacement(
                      username=pytest.config.admin_username,
                      password=pytest.config.admin_password,
                      app='search', uri_base=self.mgmt_url)
              else:
                  conn = rip.RESTConnectorReplacement(
                      username=self.username, password=self.password,
                      app='search', uri_base=self.mgmt_url)
      
              self.rest = rip.RESTInPeace(conn)
      
              # by default fwd rest and reciever rest is the same
              self.fwd_rest = self.rest
              if ('config' in pytest.__dict__ and
                      'install_forwarder' in pytest.config.__dict__ and
                      pytest.config.install_forwarder and
                      'forwarder_username' in pytest.config.__dict__ and
                      'forwarder_password' in pytest.config.__dict__):
                  conn = rip.RESTConnectorReplacement(
                      username=pytest.config.forwarder_username,
                      password=pytest.config.forwarder_password,
                      app='search', uri_base=self.mgmt_url)
                  self.fwd_rest = rip.RESTInPeace(conn)
      
              full_path = os.path.join(self.logfile_dir, self.logfile_name)
              if is_abs_path(full_path):
                  self.log_path = full_path
              else:
                  self.log_path = path_util.abspath(full_path)
      
              self.logger.info(
                  normalize_to_str("Log path: {lp}".format(lp=self.log_path)))
      
              src = (self.source.replace('\\\\', '\\\\\\\\')
                     if _platform == 'win32' else self.source)
              self.search_string = (
                  'index="{idx}" source="{src}" sourcetype="{srctype}"'.format(
                      idx=self.index, src=src, srctype=self.sourcetype))
      
          def search_string_with_timerange(self, earliest=0, latest='now'):
              """
              To provide a method that can specify the time range in log file level
              via log_file.search_string_with_timerange(), instead of modifying the
              search cmd string or uri params in each case params.
      
              :param earliest: set the earliest time , default is 0 means that starts
                               from earliest event date of log but not the from the
                               start of UTC epoch time.
              :param latest: set the latest time , default is now which used together
                             with earliest = 0 to set 'All time' timerange.
              :return: Return the search string
              """
              time_search_string = "{s} earliest={e} latest={l}".format(
                  s=self.search_string, e=earliest, l=latest)
              return time_search_string
      
          def set_rest_setting(self, endpoint, params, remote_rest=None):
              """
              Checks if a rest endpoint exist, if not creates it.  Otherwise just
              updates the endpoints parameters.
              """
              rest = remote_rest or self.rest
              name = params.pop('name')
              check_endpoint = getattr(rest, 'check_{}'.format(endpoint))
              create_endpoint = getattr(rest, 'create_{}'.format(endpoint))
              edit_endpoint = getattr(rest, 'edit_{}'.format(endpoint))
              wait_for_endpoint_to_be_created = getattr(
                  rest, 'wait_for_{}_to_be_created'.format(endpoint))
      
              if not check_endpoint(name):
                  create_endpoint(name=name, **params)
                  wait_for_endpoint_to_be_created(name)
              else:
                  edit_endpoint(name, **params)
      
              if check_endpoint(name) and endpoint == 'cloud_index':
                  self.validate_cloud_indexers(rest, name)
      
          def validate_cloud_indexers(self, rest, name):
              """
              To validate if all indexers have replicated the index from cluster
              master. In this case we get all the indexers present in indexer cluster
              and poll till each indexer has received index
              """
              self.logger.info("Verifying status of index created in indexers")
              cluster_config = json.loads(
                  rest.get_all_cluster_config(output_mode='json')[1])
              if 'entry' in cluster_config:
                  master_uri = (cluster_config[
                                'entry'][0]['content']['master_uri'])
                  conn = rip.RESTConnectorReplacement(
                      username=pytest.config.admin_username,
                      password=pytest.config.admin_password, app='search',
                      uri_base=master_uri)
                  master_rest = rip.RESTInPeace(conn)
      
                  # Now need to wait till cluster master exits maintenance mode
                  def not_in_maintenance_mode():
                      """
                      Check if the cluster master is in maintenance mode if yes
                      then wait or continue polling
                      """
                      info_content = json.loads(
                          master_rest.get_cluster_master(
                              id_name='info',
                              output_mode='json')[1])['entry'][0]['content']
                      self.logger.info("Cluster master info: {}".format(
                          info_content))
                      return (not info_content['maintenance_mode'] and
                              not info_content['rolling_restart_flag'] and
                              info_content['indexing_ready_flag'])
      
                  poll_for_condition(not_in_maintenance_mode)
      
                  # Once out of maintenance mode then we can check if each index is
                  # searchable
      
                  def is_index_searchable():
                      """
                      Check if each peer's status is now searchable.
      
                      @rtype: boolean
                      @rparam: Status of the peer is searchable.
                      """
                      peers = json.loads(
                          master_rest.get_cluster_master(
                              id_name='peers', output_mode='json')[1])
      
                      for peer in peers['entry']:
                          self.logger.info("Peer info: {}".format(peer))
                          if(peer['content']['status'] != 'Up' or
                                  not peer['content']['is_searchable']):
                              return False
                      return True
      
                  poll_for_condition(is_index_searchable)
      
          def setup(self):
              """
              Setup needed to perform for sending data.
              """
              pass
      
          def index_log(self):
              """
              Method to send data and perform indexing on that data.
              """
              pass
      
          def teardown(self):
              """
              Teardown the setup for indexing log
              """
              pass
      
          def get_current_event_count(
                  self, rest=None, poll_frequency=0.5, timeout=30):
              """
              Gets current event count during log indexing in order to wait for the
              expected event count.
      
              :type rest: RESTInPeace
              :param rest: the rest connection, using self.rest if not specified
      
              :type poll_frequency: number
              :param poll_frequency: frequency for checking the search job status
      
              :type timeout: int
              :param timeout: timeout to get current event count
      
              :rtype int
              :return current event count
              """
              rest = rest or self.rest
      
              src = (self.source.replace('\\\\', '\\\\\\\\')
                     if _platform == 'win32' else self.source)
              search_string = (
                  '| metadata type=sources index="{i}" | search source="{l}" '
                  '| appendcols [search index="{i}" source="{l}" | head 1 '
                  '| stats count as hasSearchableEvent]'.format(i=self.index, l=src))
      
              _, cont = rest.create_job(
                  search=search_string, output_mode='json')
              sid = json.loads(cont)[u'sid']
      
              def wait_for_job_done():
                  """
                  Wait for job to be done
                  """
                  job = json.loads(rest.get_job(sid, output_mode='json')[1])
                  return job['entry'][0]['content']['dispatchState'] == 'DONE'
      
              poll_for_condition(
                  wait_for_job_done,
                  frequency=poll_frequency, timeout=timeout,
                  error_message="Timeout during getting event count of "
                                "{log}".format(log=self.log_path))
      
              _, job_cont = rest.get_job(
                  sid, sub_endpoint='results', output_mode='json')
              results = json.loads(job_cont)['results']
      
              if bool(results):
                  total_count = int(json.loads(job_cont)['results'][0].get(
                      'totalCount', 0))
                  has_searchable_event = int(json.loads(job_cont)['results'][0].get(
                      'hasSearchableEvent', 0))
                  if has_searchable_event:
                      return total_count
                  else:
                      return 0
      
          def wait_for_event_count(self, rest=None, poll_frequency=0.5):
              """
              Wait for the expected event count
      
              :type rest: RESTInPeace
              :param rest: the rest connection, using the self one if not specified
      
              :type poll_frequency: number
              :param poll_frequency: frequency for checking
              """
              rest = rest or self.rest
      
              # polling wait to let the log be fully indexed
              poll_for_condition(
                  lambda: self.event_count <= self.get_current_event_count(rest),
                  frequency=poll_frequency, timeout=self.index_wait,
                  error_message='After {s} seconds, the file {f} is not completely '
                                'indexed.'.format(
                      s=self.index_wait, f=self.log_path))
      
              self.logger.info(
                  normalize_to_str('Log file {f} is completely indexed.'.format(
                      f=self.log_path)))
      
      
      class HttpInput(object):
      
          def __init__(self, host, port, token=None, ack=False, ssl=False):
              self._host = host
              self._port = port
              self._token = token
              self._is_ssl = ssl
              self._build_url()
              self._build_url_raw()
      
              self._header = {'Authorization': 'Splunk {t}'.format(t=self._token)}
              if ack:
                  self._header['x-splunk-request-channel'] = self._token
      
          def _build_url(self):
              self._url = "http{}://{}:{}/services/collector/event".format(
                  's' if self._is_ssl else '', self._host, self._port)
      
          def _build_url_raw(self):
              self._url_raw = "http{}://{}:{}/services/collector/raw".format(
                  's' if self._is_ssl else '', self._host, self._port)
      
          def send(self, payload, raw=False, host=None, index=None, source=None,
                   sourcetype=None, time=None, fields=None):
              """
              send data using HEC
      
              :param payload: the payload you want to send through hec
              :type payload: for raw=True, this is an object that will be
                             normalized to ascii str
                             for raw=False, this is an object that will be
                             json dumped
      
              :param raw: True means send using hec raw, False means send using event
              :type raw: bool
      
              :param host: host name
              :type host: str
      
              :param index: index name
              :type index: str
      
              :param source: user defined event source
              :type source: str
      
              :param sourcetype: user defined event sourcetype
              :type sourcetype: str
      
              :param time: epoch-formatted time
              :type time: str or unsigned integer
      
              :param fields: for raw=False only, fields for indexing that do not
                             occur in the event payload itself
              :type fields: dict
      
              :return: the response item
              :rtype: requests.Response
              """
              params = {}
              if raw:
                  url = self._url_raw
                  data = normalize_to_str(payload)
              else:
                  url = self._url
                  data_dict = {'event': payload}
                  if fields is not None:
                      data_dict['fields'] = fields
                  data = json.dumps(data_dict)
      
              if host is not None:
                  params['host'] = host
              if index is not None:
                  params['index'] = index
              if source is not None:
                  params['source'] = source
              if sourcetype is not None:
                  params['sourcetype'] = sourcetype
              if time is not None:
                  params['time'] = time
      
              response = requests.post(
                  url, headers=self._header, data=data, verify=False, params=params)
      
              if not response.ok:
                  raise HECRequestException(
                      'Failed to send data via HTTP Input. \\n'
                      'status code:{status_code} \\n'
                      'response content: {cont}'.format(
                          status_code=response.status_code,
                          cont=response.content))
              return response
      
      
      class HttpInputLog(IndexLog):
          """
          Class to index a log file via HTTP Input.
      
          """
      
          def __init__(
                  self, logfile_name, logfile_dir, sourcetype, event_count, index,
                  username, password, mgmt_url):
              """
              Initializes some class variables, that could be referenced later.
      
              @type logfile_name: string
              @param logfile_name: name of the log file
      
              @type logfile_dir: string
              @param logfile_dir: dir of the log file
      
              @type sourcetype: string
              @param sourcetype: name of sourcetype for the log file
      
              @type event_count: int
              @param event_count: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type username: string
              @param username: username of the admin user to make rest conn
      
              @type password: string
              @param password: password of the admin user to make rest conn
      
              @type mgmt_url: string
              @param mgmt_url: the splunkd managment url
      
              """
      
              self.token_name = '{s}_http_input'.format(s=sourcetype)
              source = 'http:{s}'.format(s=self.token_name)
      
              super(HttpInputLog, self).__init__(
                  logfile_name, logfile_dir, sourcetype, event_count, index,
                  source, username, password, mgmt_url)
      
              self.host = mgmt_url.split(':')[1].strip('//')
              self.port = 8088
      
              self.logger = logging.getLogger(self.__class__.__name__)
      
          def setup(self):
              self.rest.edit_http_input(
                  'http', enableSSL=False, port=self.port, disabled=False,
                  output_mode='json')
      
              self.rest.create_http_input(
                  name=self.token_name, sourcetype=self.sourcetype,
                  index=self.index, output_mode='json')
      
          def index_log(self):
              http_input_json = self.rest.get_http_input(
                  self.token_name, output_mode='json')[1]
              token = json.loads(http_input_json)['entry'][0]['content']['token']
              self.logger.info(
                  normalize_to_str('index log using token: {t}'.format(t=token)))
      
              http_input = HttpInput(host=self.host, port=self.port, token=token)
              with open(self.log_path) as log_file:
                  for line in log_file.readlines():
                      http_input.send(line)
      
          def teardown(self):
              if self.rest.check_http_input(self.token_name):
                  self.rest.delete_http_input(self.token_name)
      
      
      class OneshotInputLog(IndexLog):
          """
          Class to index once a log file for testing.
          """
          def __init__(
                  self, logfile_name, sourcetype, event_count, times=1, index='main',
                  logfile_dir=None, username=None, password=None, mgmt_url=None,
                  path_util=os.path, index_wait=INDEX_WAIT, rest_settings=None,
                  source=None):
              """
              Initializes some class variables, that could be referenced later.
      
              :type logfile_name: string
              :param logfile_name: name of the log file
      
              :type sourcetype: string
              :param sourcetype: name of sourcetype for the log file
      
              :type event_count: int
              :param event_count: number of events in the log file.
      
              :type times: int
              :param times: how many times of oneshot will be done
      
              :type index: string
              :param index: name of the index for the log file
      
              :type logfile_dir: string
              :param logfile_dir: dir of the log file
      
              :type username: string
              :param username: username of the admin user to make rest conn
      
              :type password: string
              :param password: password of the admin user to make rest conn
      
              :type mgmt_url: string
              :param mgmt_url: the splunkd managment url
      
              :type path_util: object
              :param path_util: the file path util
      
              :type index_wait: int
              :param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
      
              """
              if logfile_dir is None:
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              if not path_util.exists(log_path):
                  raise FileNotFound(
                      "Could not locate the file '{}'.".format(log_path))
      
              if source is None:
                  source = log_path
      
              super(OneshotInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count * times, index=index,
                  logfile_dir=logfile_dir, username=username, password=password,
                  source=source, mgmt_url=mgmt_url, path_util=path_util,
                  index_wait=index_wait, rest_settings=rest_settings)
              self.times = times
      
          def index_log(self, rest=None):
              # TODO remove rest param,  currently only used by
              # theatre/puppets/indexer.py: log_object.index_log(self.nobody_rest)
              rest = rest or self.rest
              self.logger.info(normalize_to_str(
                  "Editing indexer rest settings: {}".format(self.rest_settings)))
              try:
                  for endpoint, params in self.rest_settings.iteritems():
                      self.set_rest_setting(endpoint, params, rest)
              except Exception as err:
                  self.logger.warn(normalize_to_str(
                      "Failed to setup the index for the log file. "
                      "Tests may possibly fail. {e}".format(e=err)))
      
              for _ in range(self.times):
                  rest.create_input_oneshot(
                      output_mode='json', name=self.log_path,
                      index=self.index, sourcetype=self.sourcetype,
                      **{'rename-source': self.source})
      
      
      class MonitorInputLog(IndexLog):
          """
          Class to use for monitoring a log file for testing.
      
          """
          def __init__(
                  self, logfile_name, sourcetype, event_count, index='main',
                  logfile_dir=None, username=None, password=None, mgmt_url=None,
                  path_util=os.path, index_wait=INDEX_WAIT, rest_settings=None):
      
              """
              Initializes some class variables, that could be referenced later.
      
              @type logfile_name: string
              @param logfile_name: name of the log file
      
              @type sourcetype: string
              @param sourcetype: name of sourcetype for the log file
      
              @type event_count: int
              @param event_count: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type logfile_dir: string
              @param logfile_dir: dir of the log file
      
              @type username: string
              @param username: username of the admin user to make rest conn
      
              @type password: string
              @param password: password of the admin user to make rest conn
      
              @type mgmt_url: string
              @param mgmt_url: the splunkd managment url
      
              @type path_util: object
              @param path_util: the file path util
      
              @type index_wait: int
              @param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
      
              """
              if logfile_dir is None:
                  # attempt to look at relative src path.
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              super(MonitorInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=logfile_dir, username=username, password=password,
                  source=log_path, mgmt_url=mgmt_url, path_util=path_util,
                  index_wait=index_wait, rest_settings=rest_settings)
      
              self.logger = logging.getLogger(self.__class__.__name__)
      
          def index_log(self, fwd_rest=None, idx_rest=None):
              """
              Setting up forwarder to index data to the indexer provided
      
              @type fwd_rest RESTInPeace
              @param fwd_rest the rest connection, using the self if not specified
      
              @type idx_rest RESTInPeace
              @param idx_rest the rest connection, using the self if not specified
      
              """
              fwd_rest = fwd_rest or self.fwd_rest
              idx_rest = idx_rest or self.rest
              self.logger.info(normalize_to_str(
                  "Editing indexer rest settings: {}".format(self.rest_settings)))
              try:
                  for endpoint, params in self.rest_settings.iteritems():
                      self.set_rest_setting(endpoint, params, idx_rest)
                  self.logger.info(normalize_to_str(
                      "Monitoring the file: {f}".format(f=self.log_path)))
                  fwd_rest.create_input_monitor(
                      name=self.log_path, sourcetype=self.sourcetype,
                      index=self.index)
                  self.logger.info(
                      "Index log {l} on index {i} with sourcetype {s}".format(
                          l=self.log_path, i=self.index, s=self.sourcetype))
                  fwd_rest.wait_for_input_monitor_to_be_created(self.log_path)
      
              except Exception as err:
                  self.logger.warn(normalize_to_str(
                      "Failed to setup the index for the log file. "
                      "Tests may possibly fail. {e}".format(e=err)))
      
          def teardown(self):
              self.logger.info(normalize_to_str('Delete input monitor if necessary'))
              if self.rest.check_input_monitor(self.log_path):
                  self.rest.delete_input_monitor(self.log_path)
                  self.rest.wait_for_input_monitor_to_be_deleted(self.log_path)
      
      
      class ForwarderInputLog(IndexLog):
          """
          Class to use local splunk to monitor log and forward data to remote server.
          It will be deprecated in later. Use ForwardingInputLog instead.
          """
      
          def __init__(
                  self, logfile_name, sourcetype, event_count, index,
                  receiver_host, receiver_port,
                  receiver_username, receiver_password, receiver_mgmt_url,
                  fwd_username=None, fwd_password=None, fwd_mgmt_url=None,
                  path_util=os.path, index_wait=480, rest_settings=None,
                  data_path=None):
              """
              Initializes some class variables, that could be referenced later.
      
              @type logfile_name: string
              @param logfile_name: name of the log file
      
              @type sourcetype: string
              @param sourcetype: name of sourcetype for the log file
      
              @type event_count: int
              @param event_count: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type receiver_host: string
              @param receiver_host: hostname of the receiver
      
              @type receiver_port: string
              @param receiver_port: port number of receiveiver ready to receive
      
              @type receiver_username: string
              @param receiver_username: username of the receiver to make rest conn
      
              @type receiver_password: string
              @param receiver_password: password of the receiver to make rest conn
      
              @type receiver_mgmt_url: string
              @param receiver_mgmt_url: splunkd url of receiver
      
              @type fwd_username: string
              @param fwd_username: username of the forwarder to make rest conn
      
              @type fwd_password: string
              @param fwd_password: password of the forwarder to make rest conn
      
              @type fwd_mgmt_url: string
              @param fwd_mgmt_url: the forwarder managment url
      
              @type index_wait: int
              @param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
      
              """
      
              self.monitor_input_log = MonitorInputLog(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index, logfile_dir=data_path,
                  username=fwd_username, password=fwd_password,
                  mgmt_url=fwd_mgmt_url, path_util=path_util,
                  index_wait=index_wait, rest_settings=rest_settings)
      
              super(ForwarderInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=self.monitor_input_log.logfile_dir,
                  username=self.monitor_input_log.username,
                  password=self.monitor_input_log.password,
                  source=self.monitor_input_log.log_path,
                  mgmt_url=self.monitor_input_log.mgmt_url,
                  index_wait=index_wait, rest_settings=rest_settings)
      
              self.tcp_input_name = str(receiver_port)
              self.tcp_output_server = '{h}:{p}'.format(
                  h=receiver_host, p=receiver_port)
      
              receiver_conn = rip.RESTConnectorReplacement(
                  username=receiver_username, password=receiver_password,
                  app='search', uri_base=receiver_mgmt_url)
              self.receiver_rest = rip.RESTInPeace(receiver_conn)
              self.sourcetype_name = sourcetype
              self.logger = logging.getLogger(self.__class__.__name__)
      
          def setup(self):
              """
              Sets up input monitor on the indexer side and output monitor on
              forwarder side
              """
              self.monitor_input_log.setup()
              self.receiver_rest.create_input_tcp_cooked(
                  name=self.tcp_input_name)
              self.receiver_rest.wait_for_input_tcp_cooked_to_be_created(
                  self.tcp_input_name)
      
              self.fwd_rest.create_tcp_output_server(name=self.tcp_output_server)
              self.fwd_rest.wait_for_tcp_output_server_to_be_created(
                  self.tcp_output_server)
      
          def index_log(self):
              """
              Override the index_log function of super to pass in forwarder and
              receiver's rest object to monitor data.
              """
              self.monitor_input_log.index_log(
                  fwd_rest=self.fwd_rest, idx_rest=self.receiver_rest)
      
          def wait_for_event_count(self):
              """
              Override the super method to wait for event count at receiver/indexer
              end
              """
              self.monitor_input_log.wait_for_event_count(self.receiver_rest)
      
          def get_current_event_count(self):
              """
              Override the super method to get count of log indexed.
      
              :return:
              """
              return self.monitor_input_log.get_current_event_count(
                  self.receiver_rest)
      
          def teardown(self):
              """
              Delete the setup done at forwarder and receiver side
      
              On forwarder side, delete the tcp_output_server
              On receiver side, delete the tcp_input server
              """
              try:
                  if (hasattr(pytest.config, 'instance_type')
                          and pytest.config.instance_type != 'cloud'):
                      self.logger.info(
                          normalize_to_str('Delete tcp output server if necessary'))
                      if self.fwd_rest.check_tcp_output_server(
                              self.tcp_output_server):
                          self.fwd_rest.delete_tcp_output_server(
                              self.tcp_output_server)
                          self.fwd_rest.wait_for_tcp_output_server_to_be_deleted(
                              self.tcp_output_server)
      
                      self.logger.info(
                          normalize_to_str('Delete tcp input if necessary'))
                      if self.receiver_rest.check_input_tcp_cooked(
                              self.tcp_input_name):
                          self.receiver_rest.delete_input_tcp_cooked(
                              self.tcp_input_name)
                          self.receiver_rest.wait_for_input_tcp_cooked_to_be_deleted(
                              self.tcp_input_name)
              finally:
                  self.monitor_input_log.teardown()
      
          def monitor(self):
              """
              Method for sending and indexing the log file.
              """
              if pytest.config.instance_type != 'cloud':
                  self.setup()
              self.index_log()
              self.wait_for_event_count()
      
          def remove_monitor(self):
              """
              Remove the monitor
              """
              self.teardown()
      
      
      class MonitorLog(MonitorInputLog):
      
          """
          Class to use for monitoring a log file for testing.
          For backwards compatibility
          """
      
          def __init__(
                  self,
                  name,
                  srctype,
                  evtcnt,
                  index='main',
                  data_path=None,
                  username=None,
                  password=None,
                  index_wait=INDEX_WAIT,
                  rest_settings=None):
              """
              Initializes some class variables, that could be referenced later.
      
              @type name: string
              @param name: name of the log file
      
              @type srctype: string
              @param srctype: name of sourcetype for the log file
      
              @type evtcnt: int
              @param evtcnt: number of events in the log file.
      
              @type index: string
              @param index: name of the index for the log file
      
              @type data_path: string
              @param data_path: name of the log file
      
              @type mgmt_url: string
              @param mgmt_url: the splunk managment url
      
              @type path_util: object
              @param path_util: the file path util
      
              @type index_wait: int
              @param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              @type rest_settings: dict
              @param rest_settings: rest settings
      
              """
              super(MonitorLog, self).__init__(
                  logfile_name=name, sourcetype=srctype,
                  event_count=evtcnt, index=index,
                  logfile_dir=data_path, username=username, password=password,
                  index_wait=index_wait, rest_settings=rest_settings)
      
              self.sourcetype_name = srctype
              self.logger = logging.getLogger(self.__class__.__name__)
      
          def monitor(self):
              self.index_log()
              self.wait_for_event_count()
      
          def remove_monitor(self):
              """
              Remove the monitor
              """
              self.teardown()
      
      
      class StreamingInputLog(IndexLog):
          """
          Class to use for uploading a log file for testing.
          """
      
          def __init__(
                  self, logfile_name, sourcetype, event_count, index='main',
                  logfile_dir=None, username=None, password=None, mgmt_url=None,
                  path_util=os.path, index_wait=INDEX_WAIT, rest_settings=None):
              """
              StreamingInputLog Init
      
              :type logfile_name: string
              :param logfile_name: name of the log file
      
              :type sourcetype: string
              :param sourcetype: name of sourcetype for the log file
      
              :type event_count: int
              :param event_count: number of events in the log file.
      
              :type index: string
              :param index: name of the index for the log file
      
              :type logfile_dir: string
              :param logfile_dir: dir of the log file
      
              :type username: string
              :param username: splunk username
      
              :type password: string
              :param password: splunk password
      
              :type mgmt_url: string
              :param mgmt_url: the splunk management url
      
              :type path_util: object
              :param path_util: the file path util
      
              :type index_wait: int
              :param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              :type rest_settings: dict
              :param rest_settings: rest settings
              """
      
              if logfile_dir is None:
                  # attempt to look at relative src path.
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              # prevent splunk handling the compressed file using build-in logic
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              if (tarfile.is_tarfile(log_path) or zipfile.is_zipfile(log_path) or
                      self.is_gz_file(log_path) or
                      (bz2 is not None and self.is_bz2_file(log_path))):
                  log_path += ".extracted"
      
              super(StreamingInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=logfile_dir, username=username, password=password,
                  source=log_path, mgmt_url=mgmt_url,
                  path_util=path_util,
                  index_wait=index_wait, rest_settings=rest_settings)
              # for legacy test cases
              self.sourcetype_name = sourcetype
      
          @staticmethod
          def is_gz_file(name):
              """
              judge file type whether is gz with given file name
              :param name: the file name
              :type name: string
              :rtype: bool
              :return: if it is gz file type, then return True else False
              """
              with open(name, 'rb') as file:
                  return binascii.hexlify(file.read(2)) == b'1f8b'
      
          @staticmethod
          def is_bz2_file(name):
              """
              judge file type whether is bz2 with given file name
              :param name: the file name
              :type name: string
              :rtype: bool
              :return: if it is bz2 file type, then return True else False
              """
              with open(name, 'rb') as file:
                  return binascii.hexlify(file.read(2)) == b'425a'
      
          def index_log(self):
              """
              Index log by streaming
              """
              parsed_mgmt_url = urlparse.urlparse(self.mgmt_url)
      
              if hasattr(ssl, 'SSLContext'):
                  ssl_context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
                  conn = httplib.HTTPSConnection(
                      parsed_mgmt_url.hostname, parsed_mgmt_url.port,
                      context=ssl_context)
              else:
                  conn = httplib.HTTPSConnection(
                      parsed_mgmt_url.hostname, parsed_mgmt_url.port)
      
              conn.connect()
      
              def sent_plain_data_in_dir(dir_name):
                  """
                  read plain data in dir and sent data
                  :type dir_name: string
                  :param dir_name: the absolute path of the directory
                  """
                  for file_name in os.listdir(dir_name):
                      file_path = os.path.join(dir_name, file_name)
                      if os.path.isdir(file_path):
                          sent_plain_data_in_dir(file_path)
                      else:
                          with open(file_path) as f:
                              line = f.readline()
                              while line:
                                  conn.send(line)
                                  line = f.readline()
      
              def send_data(name):
                  """
                  send data stream to splunk, supports plain text, tar file and
                   compressed file type zip, gz and bz2
                  :param name: the given file name
                  :type name: string
                  """
                  try:
                      if tarfile.is_tarfile(name):
                          tempdir = tempfile.mkdtemp()
                          with tarfile.open(name) as tf:
                              tf.extractall(tempdir)
                          sent_plain_data_in_dir(tempdir)
      
                      elif zipfile.is_zipfile(name):
                          tempdir = tempfile.mkdtemp()
                          with zipfile.ZipFile(name, 'r') as zip_file:
                              zip_file.extractall(tempdir)
                          sent_plain_data_in_dir(tempdir)
      
                      elif self.is_gz_file(name):
                          with gzip.open(name, 'rb') as f:
                              line = f.readline()
                              while line:
                                  conn.send(line)
                                  line = f.readline()
      
                      elif bz2 is not None and self.is_bz2_file(name):
                          with bz2.BZ2File(name, 'rb') as f:
                              line = f.readline()
                              while line:
                                  conn.send(line)
                                  line = f.readline()
      
                      else:
                          with open(name) as f:
                              line = f.readline()
                              while line:
                                  conn.send(line)
                                  line = f.readline()
                  except IOError as ex:
                      self.logger.error('io error occurs', exc_info=True)
                      raise ex
      
              try:
                  url_args = {
                      'index': self.index,
                      'source': self.source,
                      'sourcetype': self.sourcetype}
                  url_params = urllib.urlencode(url_args)
      
                  stream_uri = '/services/receivers/stream?{}'.format(url_params)
                  self.logger.info('stream_uri: {}'.format(stream_uri))
                  conn.putrequest('POST', stream_uri)
      
                  auth = '{u}:{p}'.format(u=self.username, p=self.password)
                  self.logger.info('stream_auth: {}'.format(auth))
                  conn.putheader('Authorization', 'Basic {}'.format(b64encode(auth)))
                  conn.putheader('x-splunk-input-mode', 'streaming')
                  conn.endheaders()
      
                  send_data(self.log_path)
              finally:
                  conn.close()
      
      
      class ForwardingInputLog(IndexLog):
          """
          use Splunk forwarder to monitor log and forward data to remote servers
          """
          def __init__(
                  self, logfile_name, sourcetype, event_count, index,
                  receiver_port, receivers,
                  fwd_username=None, fwd_password=None, fwd_mgmt_url=None,
                  path_util=os.path, index_wait=480, rest_settings=None,
                  logfile_dir=None):
              """
              Initializes some class variables, that could be referenced later.
      
              :type logfile_name: string
              :param logfile_name: name of the log file
      
              :type sourcetype: string
              :param sourcetype: name of sourcetype for the log file
      
              :type event_count: int
              :param event_count: number of events in the log file.
      
              :type index: string
              :param index: name of the index for the log file
      
              :type receiver_port: int
              :param receiver_port: port number of receiver ready to receive
      
              :type receivers: list of puppet
              :param receivers: receivers of forwarding data. For example,
              get theatre deployment stage, receivers=stage.indexers.all(), all
              indexers in the deployment will be the receivers of forwarding data.
      
              :type fwd_username: string
              :param fwd_username: username of the forwarder to make rest conn
      
              :type fwd_password: string
              :param fwd_password: password of the forwarder to make rest conn
      
              :type fwd_mgmt_url: string
              :param fwd_mgmt_url: the forwarder management url
      
              :type index_wait: int
              :param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              :type rest_settings: dict
              :param rest_settings: rest settings
      
              """
              self.logger = logging.getLogger(self.__class__.__name__)
      
              if logfile_dir is None:
                  # attempt to look at relative src path.
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              super(ForwardingInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=logfile_dir,
                  username=fwd_username,
                  password=fwd_password,
                  source=log_path,
                  mgmt_url=fwd_mgmt_url,
                  index_wait=index_wait, rest_settings=rest_settings)
              # for legacy test cases
              self.sourcetype_name = sourcetype
              self.receivers = receivers
              self.tcp_input_name = str(receiver_port)
              self.tcp_output_group = 'search_peers_group'
      
          def setup(self):
              """
              Sets up input monitor on the indexer side and output monitor on
              forwarder side
              """
              for receiver in self.receivers:
                  with receiver.rest.namespace('nobody', 'system'):
                      receiver.rest.create_input_tcp_cooked(
                          name=self.tcp_input_name, output_mode='json')
                      receiver.rest.wait_for_input_tcp_cooked_to_be_created(
                          self.tcp_input_name)
      
              my_search_peers = [
                  '{h}:{p}'.format(
                      h=receiver.splunk.splunkd_host(),
                      p=self.tcp_input_name) for receiver in self.receivers]
      
              self.fwd_rest.create_tcp_output_group(
                  output_mode='json',
                  **{'name': self.tcp_output_group,
                     'servers': ','.join(my_search_peers)})
      
          def index_log(self):
              """
              Monitor data on forwarder
              """
              self.logger.info(normalize_to_str(
                  "Editing indexer rest settings: {}".format(self.rest_settings)))
              try:
                  self.logger.info(normalize_to_str(
                      "Monitoring the file: {f}".format(f=self.log_path)))
                  self.fwd_rest.create_input_monitor(
                      name=self.log_path, sourcetype=self.sourcetype,
                      index=self.index)
                  self.logger.info(
                      "Index log {l} on index {i} with sourcetype {s}".format(
                          l=self.log_path, i=self.index, s=self.sourcetype))
                  self.fwd_rest.wait_for_input_monitor_to_be_created(self.log_path)
      
              except Exception as err:
                  self.logger.warn(normalize_to_str(
                      "Failed to setup the index for the log file. "
                      "Tests may possibly fail. {e}".format(e=err)))
      
          def teardown(self):
              """
              Delete the setup done at forwarder and receiver side
      
              On forwarder side, delete the input monitor and tcp_output_server
              On receiver side, delete the tcp_input server
              """
              self.logger.info(
                  normalize_to_str('Delete input monitor if necessary'))
              if self.fwd_rest.check_input_monitor(self.log_path):
                  self.fwd_rest.delete_input_monitor(self.log_path)
                  self.fwd_rest.wait_for_input_monitor_to_be_deleted(self.log_path)
      
              self.logger.info(
                  normalize_to_str('Delete tcp output server if necessary'))
      
              if self.fwd_rest.check_tcp_output_group(
                      self.tcp_output_group):
                  self.fwd_rest.delete_tcp_output_group(
                      self.tcp_output_group)
                  self.fwd_rest.wait_for_tcp_output_group_to_be_deleted(
                      self.tcp_output_group)
      
              self.logger.info(
                  normalize_to_str('Delete tcp input if necessary'))
              input_name = self.tcp_input_name
              for receiver in self.receivers:
                  with receiver.rest.namespace('nobody', 'system'):
                      rest = receiver.rest
                      if rest.check_input_tcp_cooked(input_name):
                          rest.delete_input_tcp_cooked(input_name)
                          rest.wait_for_input_tcp_cooked_to_be_deleted(
                              input_name)
      
      
      class CloudForwardingInputLog(IndexLog):
          """
          use Splunk forwarder to monitor log and forward data to remote servers in
          cloud deployment
          """
          def __init__(
                  self, logfile_name, sourcetype, event_count, index,
                  fwd_username=None, fwd_password=None, fwd_mgmt_url=None,
                  path_util=os.path, index_wait=480, rest_settings=None,
                  logfile_dir=None):
              """
              CloudForwardingInputLog Init
      
              :type logfile_name: string
              :param logfile_name: name of the log file
      
              :type sourcetype: string
              :param sourcetype: name of sourcetype for the log file
      
              :type event_count: int
              :param event_count: number of events in the log file.
      
              :type index: string
              :param index: name of the index for the log file
      
              :type fwd_username: string
              :param fwd_username: username of the forwarder to make rest conn
      
              :type fwd_password: string
              :param fwd_password: password of the forwarder to make rest conn
      
              :type fwd_mgmt_url: string
              :param fwd_mgmt_url: the forwarder management url
      
              :type index_wait: int
              :param index_wait: max number of seconds to wait for
                                 the data to be indexed
      
              :type rest_settings: dict
              :param rest_settings: rest settings
      
              """
              self.logger = logging.getLogger(self.__class__.__name__)
      
              if logfile_dir is None:
                  if pytest.config.option.data_dir is not None:
                      logfile_dir = pytest.config.option.data_dir
                  else:
                      raise PathNotFoundError("Data directory not specified.")
      
              full_path = os.path.join(logfile_dir, logfile_name)
              if is_abs_path(full_path):
                  log_path = full_path
              else:
                  log_path = path_util.abspath(full_path)
      
              super(CloudForwardingInputLog, self).__init__(
                  logfile_name=logfile_name, sourcetype=sourcetype,
                  event_count=event_count, index=index,
                  logfile_dir=logfile_dir,
                  username=fwd_username,
                  password=fwd_password,
                  source=log_path,
                  mgmt_url=fwd_mgmt_url,
                  index_wait=index_wait, rest_settings=rest_settings)
              # for legacy test cases
              self.sourcetype_name = sourcetype
      
          def index_log(self):
              """
              Monitor data on forwarder
              """
              self.logger.info(normalize_to_str(
                  "Editing forwarder rest settings: {}".format(self.rest_settings)))
              try:
                  self.logger.info(normalize_to_str(
                      "Monitoring the file: {f}".format(f=self.log_path)))
                  self.rest.create_input_monitor(
                      name=self.log_path, sourcetype=self.sourcetype,
                      index=self.index)
                  self.logger.info(
                      "Index log {l} on index {i} with sourcetype {s}".format(
                          l=self.log_path, i=self.index, s=self.sourcetype))
                  self.rest.wait_for_input_monitor_to_be_created(self.log_path)
      
              except Exception as err:
                  self.logger.warn(normalize_to_str(
                      "Failed to setup the index for the log file. "
                      "Tests may possibly fail. {e}".format(e=err)))
      
          def teardown(self):
              """
              Delete the setup done at forwarder side
              """
              self.logger.info(
                  normalize_to_str('Delete input monitor if necessary'))
              if self.rest.check_input_monitor(self.log_path):
                  self.rest.delete_input_monitor(self.log_path)
                  self.rest.wait_for_input_monitor_to_be_deleted(self.log_path)
      
    '''
    linesHighlighted: []
  }
]
isStarred: false
isTrashed: false
